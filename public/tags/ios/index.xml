<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>IOS on Dickson Neoh - Personal Portfolio</title>
    <link>http://localhost:1313/tags/ios/</link>
    <description>Recent content in IOS on Dickson Neoh - Personal Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Mar 2023 11:00:15 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ios/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bringing High-Quality Image Models to Mobile: Hugging Face TIMM Meets Android &amp; iOS</title>
      <link>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</link>
      <pubDate>Thu, 16 Mar 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;ðŸŒŸ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;For many data scientist (including myself), we pride ourselves in training a model, seeing the loss graph go down, and claim victory when the test set accuracy reaches 99.99235%.&lt;/p&gt;&#xA;&lt;p&gt;Why not?&lt;/p&gt;&#xA;&lt;p&gt;This is the after all the juiciest part of the job. &amp;ldquo;Solving&amp;rdquo; one dataset after another, it may seem like anything around you can be &lt;em&gt;conquered&lt;/em&gt; with a simple &lt;code&gt;model.fit&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;That was me two years ago.&lt;/p&gt;&#xA;&lt;p&gt;The naive version of me thought that was all about it with machine learning (ML).&#xA;As long as we have a dataset, ML is the way to go.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
