<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paddy-Disease on Dickson Neoh - Personal Portfolio</title>
    <link>http://localhost:1313/tags/paddy-disease/</link>
    <description>Recent content in Paddy-Disease on Dickson Neoh - Personal Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Mar 2023 11:00:15 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/paddy-disease/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Bringing High-Quality Image Models to Mobile: Hugging Face TIMM Meets Android &amp; iOS</title>
      <link>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</link>
      <pubDate>Thu, 16 Mar 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;ðŸŒŸ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;For many data scientist (including myself), we pride ourselves in training a model, seeing the loss graph go down, and claim victory when the test set accuracy reaches 99.99235%.&lt;/p&gt;&#xA;&lt;p&gt;Why not?&lt;/p&gt;&#xA;&lt;p&gt;This is the after all the juiciest part of the job. &amp;ldquo;Solving&amp;rdquo; one dataset after another, it may seem like anything around you can be &lt;em&gt;conquered&lt;/em&gt; with a simple &lt;code&gt;model.fit&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;That was me two years ago.&lt;/p&gt;&#xA;&lt;p&gt;The naive version of me thought that was all about it with machine learning (ML).&#xA;As long as we have a dataset, ML is the way to go.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PyTorch at the Edge: Deploying Over 964 TIMM Models on Android with TorchScript and Flutter</title>
      <link>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</link>
      <pubDate>Tue, 07 Feb 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;ðŸ”¥ Motivation&lt;/h3&gt;&#xA;&lt;!-- You finally got into a Kaggle competition. You found a *getting-started notebook* written by a Kaggle Grandmaster and immediately trained a state-of-the-art (SOTA) image classification model.&#xA;&#xA;After some fiddling, you found yourself in the leaderboard topping the charts with **99.9851247\% accuracy** on the test set ðŸ˜Ž!&#xA;&#xA;Proud of your achievement you reward yourself to some rest and a good night&#39;s sleep. &#xA;And tomorrow it&#39;s time to move on to the next dataset (again). --&gt;&#xA;&lt;!-- And then..&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &lt;figure&gt;&#xA;        &lt;a href=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34; class=&#34;image-popup&#34;&gt;&#xA;            &lt;img src=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34;&#xA;                 &#xA;                 &#xA;                 &#xA;                 style=&#34;max-width: 100%; height: auto;&#34;/&gt;&#xA;        &lt;/a&gt;&#xA;        &#xA;    &lt;/figure&gt;&#xA;    &#xA; --&gt;&#xA;&lt;!-- I hope this doesn&#39;t keep you awake at night as it did for me. --&gt;&#xA;&lt;p&gt;With various high-level libraries like &lt;a href=&#34;https://keras.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Keras&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/transformers/index&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Transformer&lt;/a&gt;, and &lt;a href=&#34;https://www.fast.ai/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Fastai&lt;/a&gt;, the barrier to training SOTA models has never been lower.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
