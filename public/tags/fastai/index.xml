<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Fastai on Dickson Neoh - Personal Portfolio</title>
    <link>http://localhost:1313/tags/fastai/</link>
    <description>Recent content in Fastai on Dickson Neoh - Personal Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Feb 2023 11:00:15 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/fastai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PyTorch at the Edge: Deploying Over 964 TIMM Models on Android with TorchScript and Flutter</title>
      <link>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</link>
      <pubDate>Tue, 07 Feb 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;ðŸ”¥ Motivation&lt;/h3&gt;&#xA;&lt;!-- You finally got into a Kaggle competition. You found a *getting-started notebook* written by a Kaggle Grandmaster and immediately trained a state-of-the-art (SOTA) image classification model.&#xA;&#xA;After some fiddling, you found yourself in the leaderboard topping the charts with **99.9851247\% accuracy** on the test set ðŸ˜Ž!&#xA;&#xA;Proud of your achievement you reward yourself to some rest and a good night&#39;s sleep. &#xA;And tomorrow it&#39;s time to move on to the next dataset (again). --&gt;&#xA;&lt;!-- And then..&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &lt;figure&gt;&#xA;        &lt;a href=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34; class=&#34;image-popup&#34;&gt;&#xA;            &lt;img src=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34;&#xA;                 &#xA;                 &#xA;                 &#xA;                 style=&#34;max-width: 100%; height: auto;&#34;/&gt;&#xA;        &lt;/a&gt;&#xA;        &#xA;    &lt;/figure&gt;&#xA;    &#xA; --&gt;&#xA;&lt;!-- I hope this doesn&#39;t keep you awake at night as it did for me. --&gt;&#xA;&lt;p&gt;With various high-level libraries like &lt;a href=&#34;https://keras.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Keras&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/transformers/index&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Transformer&lt;/a&gt;, and &lt;a href=&#34;https://www.fast.ai/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Fastai&lt;/a&gt;, the barrier to training SOTA models has never been lower.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
