<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Invited-Talks on Dickson Neoh - Personal Portfolio</title>
    <link>http://localhost:44047/categories/invited-talks/</link>
    <description>Recent content in Invited-Talks on Dickson Neoh - Personal Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Oct 2022 20:48:15 +0800</lastBuildDate>
    <atom:link href="http://localhost:44047/categories/invited-talks/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>From Academia to Industry: Insights from an AI/ML Engineer</title>
      <link>http://localhost:44047/blog/podcast_ai_ml_data_talks_episode_fifteen/</link>
      <pubDate>Thu, 13 Oct 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:44047/blog/podcast_ai_ml_data_talks_episode_fifteen/</guid>
      <description>üí´ AI/ML Data Talks Podcast In this podcast episode I share about my journey and transition from academia to industry and the lessons I learned along the way.&#xA;During our chat, we talk about some of the hottest topics in machine learning, like What is MLOps? Data Drift vs Concept Drift, and Monitoring Machine Learning Model.&#xA;We also talked about some insights into the latest AI and ML trends and ecosystem.</description>
    </item>
    <item>
      <title>Applications of Edge AI with Sage Elliot at Whylabs</title>
      <link>http://localhost:44047/blog/talk_rsqrd_applications_edge_ai/</link>
      <pubDate>Thu, 29 Sep 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:44047/blog/talk_rsqrd_applications_edge_ai/</guid>
      <description>‚ú® Introduction Running AI on the Edge has become a widely discussed topic in the world of artificial intelligence. At its core, the concept of Edge AI involves putting AI algorithms as close to the user or data as possible. This is in contrast to the traditional server-based approach, where computations are carried out in remote servers, leading to slow response times and the need to transfer data back and forth.</description>
    </item>
    <item>
      <title>ML Pipelines from the Get Go (Without Tears)</title>
      <link>http://localhost:44047/blog/talk_ml_pipelines_from_the_get_go/</link>
      <pubDate>Thu, 25 Aug 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:44047/blog/talk_ml_pipelines_from_the_get_go/</guid>
      <description>üí´ Takeaways In this talk, I discussed why ML pipelines should be built from the get-go. Here are some of the key takeaways:&#xA;1Ô∏è‚É£ Despite the hype around machine learning, 55% of companies have not deployed a single ML model yet, and those who have are struggling to maintain and scale them.&#xA;2Ô∏è‚É£ Putting ML in production is not just about ML, but also about engineering. Many companies are doing more engineering than ML to solve various issues that arise in the pipeline.</description>
    </item>
    <item>
      <title>Cool Data Projects Show with Kristen - Gun Detection on CPU</title>
      <link>http://localhost:44047/blog/talk_cool_data_science_cpu_pistol_detection/</link>
      <pubDate>Tue, 23 Aug 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:44047/blog/talk_cool_data_science_cpu_pistol_detection/</guid>
      <description>üî• Introduction The rapid advancement in computer vision technology has led to the development of sophisticated models that can perform complex tasks, such as object detection and segmentation, with high accuracy. However, these models often require high computational resources and can be slow when running on a CPU. This can pose a challenge for real-time applications, such as surveillance and security, where quick detection and analysis of objects is critical.</description>
    </item>
    <item>
      <title>Leveraging Open Source Tools to Deploy Models (Without üò•)</title>
      <link>http://localhost:44047/blog/talk_tfdl_deploying_dl_without_tears/</link>
      <pubDate>Thu, 09 Jun 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:44047/blog/talk_tfdl_deploying_dl_without_tears/</guid>
      <description>üí° Introduction This talk was given to the Tensorflow Deep Learning Malaysia Facebook group during the June 2022 online meetup. The group had over 7.5k members consisting of audience from various background related to artificial intelligence in Malaysia.&#xA;The goal of the talk is to introduce the members to existing open-source tools they can use to deploy models on the cloud and edge.&#xA;Half of the audience has no experience with deep learning.</description>
    </item>
  </channel>
</rss>
