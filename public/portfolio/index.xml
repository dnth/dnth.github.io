<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dickson Neoh - Personal Portfolio</title>
    <link>http://localhost:1313/portfolio/</link>
    <description>Recent content on Dickson Neoh - Personal Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 30 Sep 2024 09:00:00 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/portfolio/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Supercharge Your PyTorch Image Models: Bag of Tricks to 8x Faster Inference with ONNX Runtime &amp; Optimizations</title>
      <link>http://localhost:1313/portfolio/supercharge_your_pytorch_image_models/</link>
      <pubDate>Mon, 30 Sep 2024 09:00:00 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/supercharge_your_pytorch_image_models/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üöÄ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;Having real-time inference is crucial for computer vision applications.&#xA;In some domains, a 1-second delay in inference could mean life or death.&lt;/p&gt;&#xA;&lt;p&gt;Imagine sitting in a self-driving car and the car takes &lt;strong&gt;one full second&lt;/strong&gt; to detect an oncoming speeding truck.&lt;/p&gt;&#xA;&lt;p&gt;Just one second too late, and you could end up in the clouds üëºüëºüëº&lt;/p&gt;&#xA;&lt;p&gt;Or if you&amp;rsquo;re lucky, you get a very up-close view of the pavement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bringing High-Quality Image Models to Mobile: Hugging Face TIMM Meets Android &amp; iOS</title>
      <link>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</link>
      <pubDate>Thu, 16 Mar 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üåü Motivation&lt;/h3&gt;&#xA;&lt;p&gt;For many data scientist (including myself), we pride ourselves in training a model, seeing the loss graph go down, and claim victory when the test set accuracy reaches 99.99235%.&lt;/p&gt;&#xA;&lt;p&gt;Why not?&lt;/p&gt;&#xA;&lt;p&gt;This is the after all the juiciest part of the job. &amp;ldquo;Solving&amp;rdquo; one dataset after another, it may seem like anything around you can be &lt;em&gt;conquered&lt;/em&gt; with a simple &lt;code&gt;model.fit&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;That was me two years ago.&lt;/p&gt;&#xA;&lt;p&gt;The naive version of me thought that was all about it with machine learning (ML).&#xA;As long as we have a dataset, ML is the way to go.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clean Up Your Digital Life: How I Found 1929 Fully Identical Images, Dark, Bright and Blurry Shots in Minutes, For Free.</title>
      <link>http://localhost:1313/portfolio/clean_up_your_digital_life/</link>
      <pubDate>Thu, 23 Feb 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/clean_up_your_digital_life/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;‚úÖ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;In today&amp;rsquo;s world of selfies and Instagram, we all take tons of photos on our phones, cameras, and other gadgets.&lt;/p&gt;&#xA;&lt;p&gt;But let&amp;rsquo;s be real, it&amp;rsquo;s easy for our photo collections to become a chaotic mess, making it impossible to find that one special memory.&lt;/p&gt;&#xA;&lt;p&gt;I mean, I&amp;rsquo;ve got &lt;em&gt;gigabytes&lt;/em&gt; of photos on my Google Photo app filled with dark shots, overly exposed shots, blurry shots, and tons of duplicate stills.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PyTorch at the Edge: Deploying Over 964 TIMM Models on Android with TorchScript and Flutter</title>
      <link>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</link>
      <pubDate>Tue, 07 Feb 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üî• Motivation&lt;/h3&gt;&#xA;&lt;!-- You finally got into a Kaggle competition. You found a *getting-started notebook* written by a Kaggle Grandmaster and immediately trained a state-of-the-art (SOTA) image classification model.&#xA;&#xA;After some fiddling, you found yourself in the leaderboard topping the charts with **99.9851247\% accuracy** on the test set üòé!&#xA;&#xA;Proud of your achievement you reward yourself to some rest and a good night&#39;s sleep. &#xA;And tomorrow it&#39;s time to move on to the next dataset (again). --&gt;&#xA;&lt;!-- And then..&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &lt;figure&gt;&#xA;        &lt;a href=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34; class=&#34;image-popup&#34;&gt;&#xA;            &lt;img src=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34;&#xA;                 &#xA;                 &#xA;                 &#xA;                 style=&#34;max-width: 100%; height: auto;&#34;/&gt;&#xA;        &lt;/a&gt;&#xA;        &#xA;    &lt;/figure&gt;&#xA;    &#xA; --&gt;&#xA;&lt;!-- I hope this doesn&#39;t keep you awake at night as it did for me. --&gt;&#xA;&lt;p&gt;With various high-level libraries like &lt;a href=&#34;https://keras.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Keras&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/transformers/index&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Transformer&lt;/a&gt;, and &lt;a href=&#34;https://www.fast.ai/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Fastai&lt;/a&gt;, the barrier to training SOTA models has never been lower.&lt;/p&gt;</description>
    </item>
    <item>
      <title>fastdup: A Powerful Tool to Manage, Clean &amp; Curate Visual Data at Scale on Your CPU - For Free.</title>
      <link>http://localhost:1313/portfolio/fastdup_manage_clean_curate/</link>
      <pubDate>Tue, 03 Jan 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/fastdup_manage_clean_curate/</guid>
      <description>&lt;p&gt;‚è≥ &lt;strong&gt;Last Updated&lt;/strong&gt;: March 27, 2023.&lt;/p&gt;&#xA;&lt;h3 id=&#34;-motivation&#34;&gt;‚úÖ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;As a data scientist, you might be tempted to jump into modeling as soon as you can.&#xA;I mean, that&amp;rsquo;s the fun part, right?&lt;/p&gt;&#xA;&lt;p&gt;But trust me, if you skip straight to modeling without taking the time to really&#xA;understand the problem and analyze the data, you&amp;rsquo;re setting yourself up for failure.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve been there.&lt;/p&gt;&#xA;&lt;p&gt;You might feel like a superstar, but you&amp;rsquo;ll have with a model that doesn&amp;rsquo;t work ü§¶‚Äç‚ôÇÔ∏è.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU</title>
      <link>http://localhost:1313/portfolio/supercharging_yolov5_180_fps_cpu/</link>
      <pubDate>Tue, 07 Jun 2022 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/supercharging_yolov5_180_fps_cpu/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üî• Motivation&lt;/h3&gt;&#xA;&lt;p&gt;After months of searching, you&amp;rsquo;ve finally found &lt;em&gt;the one&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The one object detection library that just works.&#xA;No installation hassle, no package version mismatch, and no &lt;code&gt;CUDA&lt;/code&gt; errors.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m talking about the amazingly engineered &lt;a href=&#34;https://github.com/ultralytics/yolov5&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;YOLOv5&lt;/a&gt; object detection library by &lt;a href=&#34;https://ultralytics.com/yolov5&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Ultralytics&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Elated, you quickly find an interesting dataset from &lt;a href=&#34;https://roboflow.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Roboflow&lt;/a&gt; and finally trained a state-of-the-art (SOTA) YOLOv5 model to detect firearms from image streams.&lt;/p&gt;&#xA;&lt;p&gt;You ran through a quick checklist &amp;ndash;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying GPT-J Models on a Telegram Bot with Hugging Face Hub - For Free</title>
      <link>http://localhost:1313/portfolio/deploy_gpt_hf_models_on_telegram/</link>
      <pubDate>Thu, 19 May 2022 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/deploy_gpt_hf_models_on_telegram/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üí• Motivation&lt;/h3&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>Squeezing the Best Performance Out of YOLOX with Weights and Biases</title>
      <link>http://localhost:1313/portfolio/comparing_yolox_models_weights_and_biases/</link>
      <pubDate>Wed, 11 May 2022 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/comparing_yolox_models_weights_and_biases/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üîé Motivation&lt;/h3&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>Faster than GPU: How to 10x your Object Detection Model and Deploy on CPU at 50&#43; FPS</title>
      <link>http://localhost:1313/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</link>
      <pubDate>Sat, 30 Apr 2022 15:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üö¶ Motivation&lt;/h3&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Deploy Object Detection Models on Android with Flutter</title>
      <link>http://localhost:1313/portfolio/how_to_deploy_od_models_on_android_with_flutter/</link>
      <pubDate>Sun, 17 Apr 2022 15:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/how_to_deploy_od_models_on_android_with_flutter/</guid>
      <description>&lt;h3 id=&#34;-deployment-where-ml-models-go-to-die&#34;&gt;üöë Deployment: Where ML models go to die&lt;/h3&gt;&#xA;&lt;p&gt;In this post, I will outline the basic steps to deploy ML models onto lightweight mobile devices &lt;strong&gt;easily, quickly and for free&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training a Deep Learning Model for Cell Counting in 17 Lines of Code with 17 Images</title>
      <link>http://localhost:1313/portfolio/training_dl_model_for_cell_counting/</link>
      <pubDate>Mon, 11 Apr 2022 15:07:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/training_dl_model_for_cell_counting/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üï∂Ô∏è Motivation&lt;/h3&gt;&#xA;&lt;p&gt;Many biology and medical procedures involve counting cells from images taken with a microscope.&#xA;Counting cells reveals the concentration of bacteria and viruses and gives vital information on the progress of a disease.&lt;/p&gt;&#xA;&lt;p&gt;To accomplish the counting, researchers painstakingly count the cells by hand with the assistance of a device called &lt;a href=&#34;https://www.youtube.com/watch?v=WWS9sZbGj6A&amp;amp;ab_channel=ThermoFisherScientific&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;hemocytometer&lt;/a&gt;.&#xA;This process is repetitive, tedious, and prone to errors.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;What if we could automate the counting by using an intelligent deep learning algorithm instead?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying Object Detection Models on Hugging Face Spaces</title>
      <link>http://localhost:1313/portfolio/deploy_icevision_models_on_huggingface_spaces/</link>
      <pubDate>Thu, 17 Feb 2022 13:42:56 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/deploy_icevision_models_on_huggingface_spaces/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;&#xA;&lt;p&gt;So, you‚Äôve trained a deep learning model that can detect objects from images.&#xA;Next, how can you share the awesomeness of your model with the rest of the world?&#xA;You might be a PhD student trying to get some ideas from your peers or supervisors, or a startup founder who wishes to share a minimum viable product to your clients for feedback.&#xA;But, at the same time you don&amp;rsquo;t wish to go through the hassle of dealing with MLOps.&#xA;This blog post is for you. In this post I will walk you through how to deploy your model and share them to the world for free!&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
