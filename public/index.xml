<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Dickson Neoh - Personal Portfolio</title>
    <link>http://localhost:1313/</link>
    <description>Recent content on Dickson Neoh - Personal Portfolio</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 04 Nov 2024 20:48:15 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>I Made It to GitHub Trending - My Open Source Journey</title>
      <link>http://localhost:1313/blog/i_made_it_github_trending/</link>
      <pubDate>Mon, 04 Nov 2024 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/i_made_it_github_trending/</guid>
      <description>&lt;h3 id=&#34;-introduction&#34;&gt;üëã Introduction&lt;/h3&gt;&#xA;&lt;p&gt;On October 28th, 2024 I made it to GitHub Trending! This wasn&amp;rsquo;t something I expected to happen, and I&amp;rsquo;m still in disbelief.&lt;/p&gt;&#xA;&#xA;&#xA;&#xA;&#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &lt;figure style=&#34;text-align: center;&#34;&gt;&#xA;        &lt;a href=&#34;http://localhost:1313/blog/i_made_it_github_trending/trending_developer.png&#34; class=&#34;image-popup&#34;&gt;&#xA;            &lt;img src=&#34;http://localhost:1313/blog/i_made_it_github_trending/trending_developer.png&#34;&#xA;                 alt=&#34;GitHub Trending Developer for 28th October 2024&#34; &#xA;                 width=&#34;auto&#34; &#xA;                 &#xA;                 style=&#34;max-width: 100%; height: auto;&#34;/&gt;&#xA;        &lt;/a&gt;&#xA;        &#xA;        &lt;figcaption style=&#34;font-size: 0.8em;&#34;&gt;&#xA;            &lt;p&gt;&#xA;            GitHub Trending Developer for 28th October 2024&#xA;            &#xA;                &#xA;            &#xA;            &lt;/p&gt; &#xA;        &lt;/figcaption&gt;&#xA;        &#xA;    &lt;/figure&gt;&#xA;    &#xA;&#xA;&lt;p&gt;But after all the dopamine rush, I&amp;rsquo;m back to reality and I want to share my journey on how I made it.&lt;/p&gt;&#xA;&lt;p&gt;This is mostly a note to myself and I hope it can help you too.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Supercharge Your PyTorch Image Models: Bag of Tricks to 8x Faster Inference with ONNX Runtime &amp; Optimizations</title>
      <link>http://localhost:1313/portfolio/supercharge_your_pytorch_image_models/</link>
      <pubDate>Mon, 30 Sep 2024 09:00:00 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/supercharge_your_pytorch_image_models/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üöÄ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;Having real-time inference is crucial for computer vision applications.&#xA;In some domains, a 1-second delay in inference could mean life or death.&lt;/p&gt;&#xA;&lt;p&gt;Imagine sitting in a self-driving car and the car takes &lt;strong&gt;one full second&lt;/strong&gt; to detect an oncoming speeding truck.&lt;/p&gt;&#xA;&lt;p&gt;Just one second too late, and you could end up in the clouds üëºüëºüëº&lt;/p&gt;&#xA;&lt;p&gt;Or if you&amp;rsquo;re lucky, you get a very up-close view of the pavement.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Celebrating a Milestone in the Top 2% of Global Scientists</title>
      <link>http://localhost:1313/blog/world_top_scientist/</link>
      <pubDate>Fri, 17 Nov 2023 12:00:00 +0800</pubDate>
      <guid>http://localhost:1313/blog/world_top_scientist/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m really excited to tell you that I&amp;rsquo;m one of the top 2% of scientists in the world for 2023, according to Stanford University. It&amp;rsquo;s been ten years of hard work in research and learning, and this award means a lot.&lt;/p&gt;&#xA;&lt;h3 id=&#34;-the-journey&#34;&gt;üõ§Ô∏è The Journey&lt;/h3&gt;&#xA;&lt;p&gt;When I started, it was easy.&lt;/p&gt;&#xA;&lt;p&gt;I had been in academic for some time as a student and research assistant. And I had the resources, for a good start. I thought it&amp;rsquo;s too good to be true. But reality hits mid journey.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bringing High-Quality Image Models to Mobile: Hugging Face TIMM Meets Android &amp; iOS</title>
      <link>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</link>
      <pubDate>Thu, 16 Mar 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/bringing_high_quality_image_models_to_mobile/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üåü Motivation&lt;/h3&gt;&#xA;&lt;p&gt;For many data scientist (including myself), we pride ourselves in training a model, seeing the loss graph go down, and claim victory when the test set accuracy reaches 99.99235%.&lt;/p&gt;&#xA;&lt;p&gt;Why not?&lt;/p&gt;&#xA;&lt;p&gt;This is the after all the juiciest part of the job. &amp;ldquo;Solving&amp;rdquo; one dataset after another, it may seem like anything around you can be &lt;em&gt;conquered&lt;/em&gt; with a simple &lt;code&gt;model.fit&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;That was me two years ago.&lt;/p&gt;&#xA;&lt;p&gt;The naive version of me thought that was all about it with machine learning (ML).&#xA;As long as we have a dataset, ML is the way to go.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Clean Up Your Digital Life: How I Found 1929 Fully Identical Images, Dark, Bright and Blurry Shots in Minutes, For Free.</title>
      <link>http://localhost:1313/portfolio/clean_up_your_digital_life/</link>
      <pubDate>Thu, 23 Feb 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/clean_up_your_digital_life/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;‚úÖ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;In today&amp;rsquo;s world of selfies and Instagram, we all take tons of photos on our phones, cameras, and other gadgets.&lt;/p&gt;&#xA;&lt;p&gt;But let&amp;rsquo;s be real, it&amp;rsquo;s easy for our photo collections to become a chaotic mess, making it impossible to find that one special memory.&lt;/p&gt;&#xA;&lt;p&gt;I mean, I&amp;rsquo;ve got &lt;em&gt;gigabytes&lt;/em&gt; of photos on my Google Photo app filled with dark shots, overly exposed shots, blurry shots, and tons of duplicate stills.&lt;/p&gt;</description>
    </item>
    <item>
      <title>PyTorch at the Edge: Deploying Over 964 TIMM Models on Android with TorchScript and Flutter</title>
      <link>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</link>
      <pubDate>Tue, 07 Feb 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üî• Motivation&lt;/h3&gt;&#xA;&lt;!-- You finally got into a Kaggle competition. You found a *getting-started notebook* written by a Kaggle Grandmaster and immediately trained a state-of-the-art (SOTA) image classification model.&#xA;&#xA;After some fiddling, you found yourself in the leaderboard topping the charts with **99.9851247\% accuracy** on the test set üòé!&#xA;&#xA;Proud of your achievement you reward yourself to some rest and a good night&#39;s sleep. &#xA;And tomorrow it&#39;s time to move on to the next dataset (again). --&gt;&#xA;&lt;!-- And then..&#xA;&#xA;&#xA;&#xA;&#xA;&#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &lt;figure&gt;&#xA;        &lt;a href=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34; class=&#34;image-popup&#34;&gt;&#xA;            &lt;img src=&#34;http://localhost:1313/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/meme_sleep.jpg&#34;&#xA;                 &#xA;                 &#xA;                 &#xA;                 style=&#34;max-width: 100%; height: auto;&#34;/&gt;&#xA;        &lt;/a&gt;&#xA;        &#xA;    &lt;/figure&gt;&#xA;    &#xA; --&gt;&#xA;&lt;!-- I hope this doesn&#39;t keep you awake at night as it did for me. --&gt;&#xA;&lt;p&gt;With various high-level libraries like &lt;a href=&#34;https://keras.io/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Keras&lt;/a&gt;, &lt;a href=&#34;https://huggingface.co/docs/transformers/index&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Transformer&lt;/a&gt;, and &lt;a href=&#34;https://www.fast.ai/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Fastai&lt;/a&gt;, the barrier to training SOTA models has never been lower.&lt;/p&gt;</description>
    </item>
    <item>
      <title>fastdup: A Powerful Tool to Manage, Clean &amp; Curate Visual Data at Scale on Your CPU - For Free.</title>
      <link>http://localhost:1313/portfolio/fastdup_manage_clean_curate/</link>
      <pubDate>Tue, 03 Jan 2023 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/fastdup_manage_clean_curate/</guid>
      <description>&lt;p&gt;‚è≥ &lt;strong&gt;Last Updated&lt;/strong&gt;: March 27, 2023.&lt;/p&gt;&#xA;&lt;h3 id=&#34;-motivation&#34;&gt;‚úÖ Motivation&lt;/h3&gt;&#xA;&lt;p&gt;As a data scientist, you might be tempted to jump into modeling as soon as you can.&#xA;I mean, that&amp;rsquo;s the fun part, right?&lt;/p&gt;&#xA;&lt;p&gt;But trust me, if you skip straight to modeling without taking the time to really&#xA;understand the problem and analyze the data, you&amp;rsquo;re setting yourself up for failure.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;ve been there.&lt;/p&gt;&#xA;&lt;p&gt;You might feel like a superstar, but you&amp;rsquo;ll have with a model that doesn&amp;rsquo;t work ü§¶‚Äç‚ôÇÔ∏è.&lt;/p&gt;</description>
    </item>
    <item>
      <title>From Academia to Industry: Insights from an AI/ML Engineer</title>
      <link>http://localhost:1313/blog/podcast_ai_ml_data_talks_episode_fifteen/</link>
      <pubDate>Thu, 13 Oct 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/podcast_ai_ml_data_talks_episode_fifteen/</guid>
      <description>&lt;h3 id=&#34;-aiml-data-talks-podcast&#34;&gt;üí´ AI/ML Data Talks Podcast&lt;/h3&gt;&#xA;&lt;p&gt;In this podcast episode I share about my journey and transition from academia to industry and the lessons I learned along the way.&lt;/p&gt;&#xA;&lt;p&gt;During our chat, we talk about some of the hottest topics in machine learning, like What is MLOps? Data Drift vs Concept Drift, and Monitoring Machine Learning Model.&lt;/p&gt;&#xA;&lt;p&gt;We also talked about some insights into the latest AI and ML trends and ecosystem. Specifically how important it is for various tools to be able to communicate with each other, and how &lt;a href=&#34;https://zenml.io/home&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;ZenML&lt;/a&gt; helps with that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Applications of Edge AI with Sage Elliot at Whylabs</title>
      <link>http://localhost:1313/blog/talk_rsqrd_applications_edge_ai/</link>
      <pubDate>Thu, 29 Sep 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/talk_rsqrd_applications_edge_ai/</guid>
      <description>&lt;h3 id=&#34;-introduction&#34;&gt;‚ú® Introduction&lt;/h3&gt;&#xA;&lt;p&gt;Running AI on the Edge has become a widely discussed topic in the world of artificial intelligence. At its core, the concept of Edge AI involves putting AI algorithms as close to the user or data as possible. This is in contrast to the traditional server-based approach, where computations are carried out in remote servers, leading to slow response times and the need to transfer data back and forth.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ML Pipelines from the Get Go (Without Tears)</title>
      <link>http://localhost:1313/blog/talk_ml_pipelines_from_the_get_go/</link>
      <pubDate>Thu, 25 Aug 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/talk_ml_pipelines_from_the_get_go/</guid>
      <description>&lt;h3 id=&#34;-takeaways&#34;&gt;üí´ Takeaways&lt;/h3&gt;&#xA;&lt;p&gt;In this talk, I discussed why ML pipelines should be built from the get-go. Here are some of the key takeaways:&lt;/p&gt;&#xA;&lt;p&gt;1Ô∏è‚É£ Despite the hype around machine learning, 55% of companies have not deployed a single ML model yet, and those who have are struggling to maintain and scale them.&lt;/p&gt;&#xA;&lt;p&gt;2Ô∏è‚É£ Putting ML in production is not just about ML, but also about engineering. Many companies are doing more engineering than ML to solve various issues that arise in the pipeline.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cool Data Projects Show with Kristen - Gun Detection on CPU</title>
      <link>http://localhost:1313/blog/talk_cool_data_science_cpu_pistol_detection/</link>
      <pubDate>Tue, 23 Aug 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/talk_cool_data_science_cpu_pistol_detection/</guid>
      <description>&lt;h3 id=&#34;-introduction&#34;&gt;üî• Introduction&lt;/h3&gt;&#xA;&lt;p&gt;The rapid advancement in computer vision technology has led to the development of sophisticated models that can perform complex tasks, such as object detection and segmentation, with high accuracy. However, these models often require high computational resources and can be slow when running on a CPU. This can pose a challenge for real-time applications, such as surveillance and security, where quick detection and analysis of objects is critical.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Leveraging Open Source Tools to Deploy Models (Without üò•)</title>
      <link>http://localhost:1313/blog/talk_tfdl_deploying_dl_without_tears/</link>
      <pubDate>Thu, 09 Jun 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/talk_tfdl_deploying_dl_without_tears/</guid>
      <description>&lt;h3 id=&#34;-introduction&#34;&gt;üí° Introduction&lt;/h3&gt;&#xA;&#xA;&#xA;&#xA;&#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &#xA;    &lt;figure&gt;&#xA;        &lt;a href=&#34;http://localhost:1313/blog/talk_tfdl_deploying_dl_without_tears/aboutme.png&#34; class=&#34;image-popup&#34;&gt;&#xA;            &lt;img src=&#34;http://localhost:1313/blog/talk_tfdl_deploying_dl_without_tears/aboutme.png&#34;&#xA;                 &#xA;                 &#xA;                 &#xA;                 style=&#34;max-width: 100%; height: auto;&#34;/&gt;&#xA;        &lt;/a&gt;&#xA;        &#xA;    &lt;/figure&gt;&#xA;    &#xA;&#xA;&lt;p&gt;This talk was given to the Tensorflow Deep Learning Malaysia Facebook &lt;a href=&#34;https://www.facebook.com/groups/TensorFlowMY/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;group&lt;/a&gt; during the June 2022 online meetup.&#xA;The group had over 7.5k members consisting of audience from various background related to artificial intelligence in Malaysia.&lt;/p&gt;&#xA;&lt;p&gt;The goal of the talk is to introduce the members to existing open-source tools they can use to deploy models on the cloud and edge.&lt;/p&gt;&#xA;&lt;p&gt;Half of the audience has no experience with deep learning.&#xA;Hence, the talk was tailored to beginners in the field.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU</title>
      <link>http://localhost:1313/portfolio/supercharging_yolov5_180_fps_cpu/</link>
      <pubDate>Tue, 07 Jun 2022 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/supercharging_yolov5_180_fps_cpu/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üî• Motivation&lt;/h3&gt;&#xA;&lt;p&gt;After months of searching, you&amp;rsquo;ve finally found &lt;em&gt;the one&lt;/em&gt;.&lt;/p&gt;&#xA;&lt;p&gt;The one object detection library that just works.&#xA;No installation hassle, no package version mismatch, and no &lt;code&gt;CUDA&lt;/code&gt; errors.&lt;/p&gt;&#xA;&lt;p&gt;I&amp;rsquo;m talking about the amazingly engineered &lt;a href=&#34;https://github.com/ultralytics/yolov5&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;YOLOv5&lt;/a&gt; object detection library by &lt;a href=&#34;https://ultralytics.com/yolov5&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Ultralytics&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Elated, you quickly find an interesting dataset from &lt;a href=&#34;https://roboflow.com/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Roboflow&lt;/a&gt; and finally trained a state-of-the-art (SOTA) YOLOv5 model to detect firearms from image streams.&lt;/p&gt;&#xA;&lt;p&gt;You ran through a quick checklist &amp;ndash;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying GPT-J Models on a Telegram Bot with Hugging Face Hub - For Free</title>
      <link>http://localhost:1313/portfolio/deploy_gpt_hf_models_on_telegram/</link>
      <pubDate>Thu, 19 May 2022 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/deploy_gpt_hf_models_on_telegram/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üí• Motivation&lt;/h3&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>Squeezing the Best Performance Out of YOLOX with Weights and Biases</title>
      <link>http://localhost:1313/portfolio/comparing_yolox_models_weights_and_biases/</link>
      <pubDate>Wed, 11 May 2022 11:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/comparing_yolox_models_weights_and_biases/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üîé Motivation&lt;/h3&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>Faster than GPU: How to 10x your Object Detection Model and Deploy on CPU at 50&#43; FPS</title>
      <link>http://localhost:1313/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</link>
      <pubDate>Sat, 30 Apr 2022 15:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üö¶ Motivation&lt;/h3&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Deploy Object Detection Models on Android with Flutter</title>
      <link>http://localhost:1313/portfolio/how_to_deploy_od_models_on_android_with_flutter/</link>
      <pubDate>Sun, 17 Apr 2022 15:00:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/how_to_deploy_od_models_on_android_with_flutter/</guid>
      <description>&lt;h3 id=&#34;-deployment-where-ml-models-go-to-die&#34;&gt;üöë Deployment: Where ML models go to die&lt;/h3&gt;&#xA;&lt;p&gt;In this post, I will outline the basic steps to deploy ML models onto lightweight mobile devices &lt;strong&gt;easily, quickly and for free&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;style type=&#34;text/css&#34;&gt;&#xA;    .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice&#xA;    p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0&#xA;    0;font-weight:700;color:#fff;background:#6ab0de; text-transform:uppercase}.notice.warning&#xA;    .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info&#xA;    .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note&#xA;    .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip&#xA;    .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice&#xA;    img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline&#xA;    svg{top:0.125em;position:relative}&lt;/style&gt;&#xA;    &lt;div&gt;&lt;svg width=&#34;0&#34; height=&#34;0&#34; display=&#34;none&#34; xmlns=&#34;http://www.w3.org/2000/svg&#34;&gt;&#xA;            &lt;symbol id=&#34;tip-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379 0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628 0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628 0l-22.627 22.627c-6.248 6.248-6.248 16.379 0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;note-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;warning-notice&#34; viewBox=&#34;0 0 576 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937 0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154 0l239.94 416.028zM288 354c-25.405 0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346l7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373 0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884 0-12.356 5.78-11.981 12.654z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;            &lt;symbol id=&#34;info-notice&#34; viewBox=&#34;0 0 512 512&#34; preserveAspectRatio=&#34;xMidYMid meet&#34;&gt;&#xA;                &lt;path&#xA;                    d=&#34;M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196 0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627 0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627 0 12 5.373 12 12v100h12c6.627 0 12 5.373 12 12v24z&#34; /&gt;&#xA;            &lt;/symbol&gt;&#xA;        &lt;/svg&gt;&lt;/div&gt;&lt;div class=&#34;notice tip&#34; &gt;&#xA;        &lt;p class=&#34;first notice-title&#34;&gt;&lt;span class=&#34;icon-notice baseline&#34;&gt;&lt;svg&gt;&#xA;                    &lt;use href=&#34;#tip-notice&#34;&gt;&lt;/use&gt;&#xA;                &lt;/svg&gt;&lt;/span&gt;tip&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training a Deep Learning Model for Cell Counting in 17 Lines of Code with 17 Images</title>
      <link>http://localhost:1313/portfolio/training_dl_model_for_cell_counting/</link>
      <pubDate>Mon, 11 Apr 2022 15:07:15 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/training_dl_model_for_cell_counting/</guid>
      <description>&lt;h3 id=&#34;-motivation&#34;&gt;üï∂Ô∏è Motivation&lt;/h3&gt;&#xA;&lt;p&gt;Many biology and medical procedures involve counting cells from images taken with a microscope.&#xA;Counting cells reveals the concentration of bacteria and viruses and gives vital information on the progress of a disease.&lt;/p&gt;&#xA;&lt;p&gt;To accomplish the counting, researchers painstakingly count the cells by hand with the assistance of a device called &lt;a href=&#34;https://www.youtube.com/watch?v=WWS9sZbGj6A&amp;amp;ab_channel=ThermoFisherScientific&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;hemocytometer&lt;/a&gt;.&#xA;This process is repetitive, tedious, and prone to errors.&lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;What if we could automate the counting by using an intelligent deep learning algorithm instead?&lt;/em&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Contributing to open-source: Lessons learned</title>
      <link>http://localhost:1313/blog/contributing_to_open_source_lessons_learned/</link>
      <pubDate>Mon, 04 Apr 2022 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/contributing_to_open_source_lessons_learned/</guid>
      <description>&lt;h3 id=&#34;-introduction&#34;&gt;‚òÄÔ∏è Introduction&lt;/h3&gt;&#xA;&lt;p&gt;I was recently given the recognition by the folks at &lt;a href=&#34;https://github.com/airctic/icevision&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;IceVision&lt;/a&gt; to be part of the core-developer team!&#xA;&lt;a href=&#34;https://www.linkedin.com/in/farid-hassainia-ca/&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;Farid Hassainia&lt;/a&gt;, a co-creator of the IceVision Tweeted about it on March 17, 2022.&#xA;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;We are super excited to introduce you to our üéâNew Core-Dev: Dickson Neoh &lt;a href=&#34;https://twitter.com/dicksonneoh7?ref_src=twsrc%5Etfw&#34;&gt;@dicksonneoh7&lt;/a&gt;&lt;br&gt;&lt;br&gt;Dickson is actively contributing to IceVision. He ardently helps IceVision users in our Discord Community.&lt;br&gt;&lt;br&gt;We are very happy to have him on our team! &lt;a href=&#34;https://t.co/SO1qLHkarm&#34;&gt;pic.twitter.com/SO1qLHkarm&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deploying Object Detection Models on Hugging Face Spaces</title>
      <link>http://localhost:1313/portfolio/deploy_icevision_models_on_huggingface_spaces/</link>
      <pubDate>Thu, 17 Feb 2022 13:42:56 +0800</pubDate>
      <guid>http://localhost:1313/portfolio/deploy_icevision_models_on_huggingface_spaces/</guid>
      <description>&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;&#xA;&lt;p&gt;So, you‚Äôve trained a deep learning model that can detect objects from images.&#xA;Next, how can you share the awesomeness of your model with the rest of the world?&#xA;You might be a PhD student trying to get some ideas from your peers or supervisors, or a startup founder who wishes to share a minimum viable product to your clients for feedback.&#xA;But, at the same time you don&amp;rsquo;t wish to go through the hassle of dealing with MLOps.&#xA;This blog post is for you. In this post I will walk you through how to deploy your model and share them to the world for free!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Digital Logic Design - Course</title>
      <link>http://localhost:1313/blog/course_digital_logic_design/</link>
      <pubDate>Tue, 07 Sep 2021 20:48:15 +0800</pubDate>
      <guid>http://localhost:1313/blog/course_digital_logic_design/</guid>
      <description>&lt;p&gt;A collection of recorded lecture classes for the Digital Logic Design course I taught at National Energy University, Malaysia.&lt;/p&gt;&#xA;&lt;p&gt;View the playlist &lt;a href=&#34;https://www.youtube.com/playlist?list=PLqGyAx3n9NxriN8V6ar-x-GFnkAtkTL1n&#34; target=&#34;_blank&#34; rel=&#34;nofollow noopener noreferrer&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
