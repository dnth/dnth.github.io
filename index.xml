<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Dickson Neoh - Personal Portfolio</title><link>https://dicksonneoh.com/</link><description>Recent content on Dickson Neoh - Personal Portfolio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 16 Sep 2023 11:00:15 +0800</lastBuildDate><atom:link href="https://dicksonneoh.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Convert Any Model from PyTorch Image Models (TIMM) into ONNX</title><link>https://dicksonneoh.com/blog/convert_timm_onnx/</link><pubDate>Sat, 16 Sep 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/convert_timm_onnx/</guid><description>‚úÖ Motivation Making models smaller and more efficient for edge deployment.
Torch Image Model (TIMM) from urllib.request import urlopen from PIL import Image import timm img = Image.open(urlopen( &amp;#39;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png&amp;#39; )) model = timm.create_model( &amp;#39;vit_small_patch14_dinov2.lvd142m&amp;#39;, pretrained=True, num_classes=0, # remove classifier nn.Linear ) model = model.eval() # get model specific transforms (normalization, resize) data_config = timm.data.resolve_model_data_config(model) transforms = timm.data.create_transform(**data_config, is_training=False) output = model(transforms(img).unsqueeze(0)) # output is (batch_size, num_features) shaped tensor # or equivalently (without needing to set num_classes=0) output = model.</description></item><item><title>Bringing High-Quality Image Models to Mobile: Hugging Face TIMM Meets Android &amp; iOS</title><link>https://dicksonneoh.com/portfolio/bringing_high_quality_image_models_to_mobile/</link><pubDate>Thu, 16 Mar 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/bringing_high_quality_image_models_to_mobile/</guid><description>üåü Motivation For many data scientist (including myself), we pride ourselves in training a model, seeing the loss graph go down, and claim victory when the test set accuracy reaches 99.99235%.
Why not?
This is the after all the juiciest part of the job. &amp;ldquo;Solving&amp;rdquo; one dataset after another, it may seem like anything around you can be conquered with a simple model.fit.
That was me two years ago.
The naive version of me thought that was all about it with machine learning (ML).</description></item><item><title>Clean Up Your Digital Life: How I Found 1929 Fully Identical Images, Dark, Bright and Blurry Shots in Minutes, For Free.</title><link>https://dicksonneoh.com/blog/clean_up_your_digital_life/</link><pubDate>Thu, 23 Feb 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/clean_up_your_digital_life/</guid><description>‚úÖ Motivation In today&amp;rsquo;s world of selfies and Instagram, we all take tons of photos on our phones, cameras, and other gadgets.
But let&amp;rsquo;s be real, it&amp;rsquo;s easy for our photo collections to become a chaotic mess, making it impossible to find that one special memory.
I mean, I&amp;rsquo;ve got gigabytes of photos on my Google Photo app filled with dark shots, overly exposed shots, blurry shots, and tons of duplicate stills.</description></item><item><title>PyTorch at the Edge: Deploying Over 964 TIMM Models on Android with TorchScript and Flutter</title><link>https://dicksonneoh.com/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</link><pubDate>Tue, 07 Feb 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</guid><description>üî• Motivation With various high-level libraries like Keras, Transformer, and Fastai, the barrier to training SOTA models has never been lower.
On top of that with platforms like Google Colab and Kaggle, pretty much anyone can train a reasonably good model using an old laptop or even a mobile phone (with some patience).
The question is no longer &amp;ldquo;can we train a SOTA model?&amp;rdquo;, but &amp;ldquo;what happens after that?&amp;rdquo;
Unfortunately, after getting the model trained, most people wash their hands off at this point claiming their model works.</description></item><item><title>fastdup: A Powerful Tool to Manage, Clean &amp; Curate Visual Data at Scale on Your CPU - For Free.</title><link>https://dicksonneoh.com/portfolio/fastdup_manage_clean_curate/</link><pubDate>Tue, 03 Jan 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/fastdup_manage_clean_curate/</guid><description>‚è≥ Last Updated: March 27, 2023.
‚úÖ Motivation As a data scientist, you might be tempted to jump into modeling as soon as you can. I mean, that&amp;rsquo;s the fun part, right?
But trust me, if you skip straight to modeling without taking the time to really understand the problem and analyze the data, you&amp;rsquo;re setting yourself up for failure.
I&amp;rsquo;ve been there.
You might feel like a superstar, but you&amp;rsquo;ll have with a model that doesn&amp;rsquo;t work ü§¶‚Äç‚ôÇÔ∏è.</description></item><item><title>From Academia to Industry: Insights from an AI/ML Engineer</title><link>https://dicksonneoh.com/blog/podcast_ai_ml_data_talks_episode_fifteen/</link><pubDate>Thu, 13 Oct 2022 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/podcast_ai_ml_data_talks_episode_fifteen/</guid><description>üí´ AI/ML Data Talks Podcast In this podcast episode I share about my journey and transition from academia to industry and the lessons I learned along the way.
During our chat, we talk about some of the hottest topics in machine learning, like What is MLOps? Data Drift vs Concept Drift, and Monitoring Machine Learning Model.
We also talked about some insights into the latest AI and ML trends and ecosystem.</description></item><item><title>Applications of Edge AI with Sage Elliot at Whylabs</title><link>https://dicksonneoh.com/blog/talk_rsqrd_applications_edge_ai/</link><pubDate>Thu, 29 Sep 2022 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/talk_rsqrd_applications_edge_ai/</guid><description>‚ú® Introduction Running AI on the Edge has become a widely discussed topic in the world of artificial intelligence. At its core, the concept of Edge AI involves putting AI algorithms as close to the user or data as possible. This is in contrast to the traditional server-based approach, where computations are carried out in remote servers, leading to slow response times and the need to transfer data back and forth.</description></item><item><title>ML Pipelines from the Get Go (Without Tears)</title><link>https://dicksonneoh.com/blog/talk_ml_pipelines_from_the_get_go/</link><pubDate>Thu, 25 Aug 2022 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/talk_ml_pipelines_from_the_get_go/</guid><description>üí´ Takeaways In this talk, I discussed why ML pipelines should be built from the get-go. Here are some of the key takeaways:
1Ô∏è‚É£ Despite the hype around machine learning, 55% of companies have not deployed a single ML model yet, and those who have are struggling to maintain and scale them.
2Ô∏è‚É£ Putting ML in production is not just about ML, but also about engineering. Many companies are doing more engineering than ML to solve various issues that arise in the pipeline.</description></item><item><title>Cool Data Projects Show with Kristen - Gun Detection on CPU</title><link>https://dicksonneoh.com/blog/talk_cool_data_science_cpu_pistol_detection/</link><pubDate>Tue, 23 Aug 2022 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/talk_cool_data_science_cpu_pistol_detection/</guid><description>üî• Introduction The rapid advancement in computer vision technology has led to the development of sophisticated models that can perform complex tasks, such as object detection and segmentation, with high accuracy. However, these models often require high computational resources and can be slow when running on a CPU. This can pose a challenge for real-time applications, such as surveillance and security, where quick detection and analysis of objects is critical.</description></item><item><title>Leveraging Open Source Tools to Deploy Models (Without üò•)</title><link>https://dicksonneoh.com/blog/talk_tfdl_deploying_dl_without_tears/</link><pubDate>Thu, 09 Jun 2022 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/talk_tfdl_deploying_dl_without_tears/</guid><description>üí° Introduction This talk was given to the Tensorflow Deep Learning Malaysia Facebook group during the June 2022 online meetup. The group had over 7.5k members consisting of audience from various background related to artificial intelligence in Malaysia.
The goal of the talk is to introduce the members to existing open-source tools they can use to deploy models on the cloud and edge.
Half of the audience has no experience with deep learning.</description></item><item><title>Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU</title><link>https://dicksonneoh.com/portfolio/supercharging_yolov5_180_fps_cpu/</link><pubDate>Tue, 07 Jun 2022 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/supercharging_yolov5_180_fps_cpu/</guid><description>üî• Motivation After months of searching, you&amp;rsquo;ve finally found the one.
The one object detection library that just works. No installation hassle, no package version mismatch, and no CUDA errors.
I&amp;rsquo;m talking about the amazingly engineered YOLOv5 object detection library by Ultralytics.
Elated, you quickly find an interesting dataset from Roboflow and finally trained a state-of-the-art (SOTA) YOLOv5 model to detect firearms from image streams.
You ran through a quick checklist &amp;ndash;</description></item><item><title>Deploying GPT-J Models on a Telegram Bot with Hugging Face Hub - For Free</title><link>https://dicksonneoh.com/portfolio/deploy_gpt_hf_models_on_telegram/</link><pubDate>Thu, 19 May 2022 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/deploy_gpt_hf_models_on_telegram/</guid><description>üí• Motivation tip
By the end of this post you will learn how to:
Set up a Telegram bot with a Python wrapper library. Use the Gradio API to access the GPT-J model prediction. Host the Telegram bot on Hugging Face Spaces. By the end of this post, you&amp;rsquo;ll have your own Telegram bot that has access to the GPT-J-6B model. All for free.
Deploying a state-of-the-art (SOTA) GPT-like language model on a chatbot can be tricky.</description></item><item><title>Squeezing the Best Performance Out of YOLOX with Weights and Biases</title><link>https://dicksonneoh.com/portfolio/comparing_yolox_models_weights_and_biases/</link><pubDate>Wed, 11 May 2022 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/comparing_yolox_models_weights_and_biases/</guid><description>üîé Motivation tip
By the end of this post you will learn how to:
Install the Weights and Biases client and log the YOLOX training metrics. Compare training metrics on Weights and Biases dashboard. Picking the best model with mAP and FPS values. &amp;ldquo;So many models, so little time!&amp;rdquo;
As a machine learning engineer, I often hear this phrase thrown around in many variations.
In object detection alone, there are already several hundreds of models out there.</description></item><item><title>Faster than GPU: How to 10x your Object Detection Model and Deploy on CPU at 50+ FPS</title><link>https://dicksonneoh.com/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</link><pubDate>Sat, 30 Apr 2022 15:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</guid><description>üö¶ Motivation tip
By the end of this post, you will learn how to:
Train state-of-the-art YOLOX model with your own data. Convert the YOLOX PyTorch model into ONNX and OpenVINO IR format. Run quantization algorithm to 10x your model&amp;rsquo;s inference speed. P/S: The final model runs faster on the CPU than the GPU! üò±
Deep learning (DL), seems to be the magic word that makes anything mundane cool again. We find them everywhere - in news reports, blog posts, articles, research papers, advertisements, and even baby books.</description></item><item><title>How to Deploy Object Detection Models on Android with Flutter</title><link>https://dicksonneoh.com/portfolio/how_to_deploy_od_models_on_android_with_flutter/</link><pubDate>Sun, 17 Apr 2022 15:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/how_to_deploy_od_models_on_android_with_flutter/</guid><description>üöë Deployment: Where ML models go to die In this post, I will outline the basic steps to deploy ML models onto lightweight mobile devices easily, quickly and for free.
tip
By the end of this post, you will learn about:
Leveraging Hugging Face infrastructure to host models. Deploying on any edge device using REST API. Displaying the results on a Flutter Android app. According to Gartner, more than 85% of machine learning (ML) models never made it into production.</description></item><item><title>Training a Deep Learning Model for Cell Counting in 17 Lines of Code with 17 Images</title><link>https://dicksonneoh.com/portfolio/training_dl_model_for_cell_counting/</link><pubDate>Mon, 11 Apr 2022 15:07:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/training_dl_model_for_cell_counting/</guid><description>üï∂Ô∏è Motivation Many biology and medical procedures involve counting cells from images taken with a microscope. Counting cells reveals the concentration of bacteria and viruses and gives vital information on the progress of a disease.
To accomplish the counting, researchers painstakingly count the cells by hand with the assistance of a device called hemocytometer. This process is repetitive, tedious, and prone to errors.
What if we could automate the counting by using an intelligent deep learning algorithm instead?</description></item><item><title>Contributing to open-source: Lessons learned</title><link>https://dicksonneoh.com/blog/contributing_to_open_source_lessons_learned/</link><pubDate>Mon, 04 Apr 2022 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/contributing_to_open_source_lessons_learned/</guid><description>‚òÄÔ∏è Introduction I was recently given the recognition by the folks at IceVision to be part of the core-developer team! Farid Hassainia, a co-creator of the IceVision Tweeted about it on March 17, 2022. We are super excited to introduce you to our üéâNew Core-Dev: Dickson Neoh @dicksonneoh7
Dickson is actively contributing to IceVision. He ardently helps IceVision users in our Discord Community.
We are very happy to have him on our team!</description></item><item><title>Deploying Object Detection Models on Hugging Face Spaces</title><link>https://dicksonneoh.com/portfolio/deploy_icevision_models_on_huggingface_spaces/</link><pubDate>Thu, 17 Feb 2022 13:42:56 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/deploy_icevision_models_on_huggingface_spaces/</guid><description>Introduction So, you‚Äôve trained a deep learning model that can detect objects from images. Next, how can you share the awesomeness of your model with the rest of the world? You might be a PhD student trying to get some ideas from your peers or supervisors, or a startup founder who wishes to share a minimum viable product to your clients for feedback. But, at the same time you don&amp;rsquo;t wish to go through the hassle of dealing with MLOps.</description></item><item><title>Digital Logic Design - Course</title><link>https://dicksonneoh.com/blog/course_digital_logic_design/</link><pubDate>Tue, 07 Sep 2021 20:48:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/course_digital_logic_design/</guid><description>A collection of recorded lecture classes for the Digital Logic Design course I taught at National Energy University, Malaysia.
View the playlist here</description></item></channel></rss>