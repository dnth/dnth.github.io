<!doctype html><html><head><meta charset=utf-8><title>Deploy IceVision Models on HuggingFace Spaces</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><link rel=stylesheet href=https://dicksonneoh.com/plugins/slick/slick.css><link rel=stylesheet href=https://dicksonneoh.com/plugins/slick/slick-theme.css><link rel=stylesheet href=https://dicksonneoh.com/plugins/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=https://dicksonneoh.com/plugins/magnafic-popup/magnific-popup.css><link href=https://dicksonneoh.com/scss/style.min.css rel=stylesheet><link rel="shortcut icon" href=https://dicksonneoh.com/images/favicon.ico type=image/x-icon><link rel=icon href=https://dicksonneoh.com/images/favicon.png type=image/x-icon><script async src="https://www.googletagmanager.com/gtag/js?id=YOUR%20GOOGLE%20ANALYTICS%20CODE"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','YOUR GOOGLE ANALYTICS CODE')</script></head><body><nav class="navbar navbar-expand-lg fixed-top"><div class=container><a href=https://dicksonneoh.com/ class=navbar-brand><img src=https://dicksonneoh.com/images/site-navigation/logo_dn_resize.png alt=site-logo></a>
<button type=button class="navbar-toggler collapsed" data-toggle=collapse data-target=#navbarCollapse>
<span class=navbar-toggler-icon></span><span class=navbar-toggler-icon></span><span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-between" id=navbarCollapse><ul class="nav navbar-nav main-navigation my-0 mx-auto"><li class=nav-item><a href=https://dicksonneoh.com/#home class="nav-link text-dark text-sm-center p-2">Home</a></li><li class=nav-item><a href=https://dicksonneoh.com/#about class="nav-link text-dark text-sm-center p-2">About</a></li><li class=nav-item><a href=https://dicksonneoh.com/#service class="nav-link text-dark text-sm-center p-2">Service</a></li><li class=nav-item><a href=https://dicksonneoh.com/#resume class="nav-link text-dark text-sm-center p-2">Resume</a></li><li class=nav-item><a href=https://dicksonneoh.com/#skills class="nav-link text-dark text-sm-center p-2">Skills</a></li><li class=nav-item><a href=https://dicksonneoh.com/#blog class="nav-link text-dark text-sm-center p-2">Blog</a></li><li class=nav-item><a href=https://dicksonneoh.com/#contact class="nav-link text-dark text-sm-center p-2">Contact</a></li></ul><div class=navbar-nav><a href=https://dicksonneoh.com/contact class="btn btn-primary btn-zoom hire_button">Hire Me Now</a></div></div></div></nav><div id=content><header class=breadCrumb><div class=container><div class=row><div class="col-lg-10 col-md-12 offset-lg-1 offset-md-0 text-center"><h3 class=breadCrumb__title>Deploy IceVision Models on HuggingFace Spaces</h3><nav aria-label=breadcrumb class="d-flex justify-content-center"><ol class="breadcrumb align-items-center"><li class=breadcrumb-item><a href=https://dicksonneoh.com/>Home</a></li><li class=breadcrumb-item><a href=https://dicksonneoh.com/blog>All Post</a></li><li class="breadcrumb-item active" aria-current=page>Deploy IceVision Models on HuggingFace Spaces</li></ol></nav></div></div></div></header><section class="section singleBlog"><div class=svg-img><img src=https://dicksonneoh.com/images/hero/figure-svg.svg alt></div><div class=animate-shape><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 600 600"><defs><linearGradient id="d" x1=".929" y1=".111" x2=".263" y2=".935" gradientUnits="objectBoundingBox"><stop offset="0" stop-color="#f1f6f9"/><stop offset="1" stop-color="#f1f6f9" stop-opacity="0"/></linearGradient></defs><g data-name="blob-shape (3)"><path class="blob" fill="url(#d)" d="M455.4 151.1c43.1 36.7 73.4 92.8 60.8 136.3-12.7 43.5-68.1 74.4-111.3 119.4-43.1 45-74 104.1-109.8 109-35.9 5-76.7-44.2-111.8-89.2-35.2-45-64.7-85.8-70.8-132.6-6-46.8 11.6-99.6 46.7-136.3 35.2-36.6 88-57.2 142.4-58.8 54.5-1.7 110.6 15.6 153.8 52.2z"/></g></svg></div><div class=animate-pattern><img src=https://dicksonneoh.com/images/service/background-pattern.svg alt=background-shape></div><div class=container><div class=row><div class=col-lg-12><div class=singleBlog__feature><img src=https://dicksonneoh.com/images/blog/deploy-icevision-hfspace/train-deploy-share.png alt=feature-image></div></div></div><div class="row mt-5"><div class=col-lg-12><div class=singleBlog__content><h3 id=introduction>Introduction</h3><p>So, you’ve trained a deep learning model that can detect objects from images.
Next, how can you share the awesomeness of your model with the rest of the world?
You might be a PhD student trying to get some ideas from your peers or supervisors, or a startup founder who wishes to share a minimum viable product to your clients for feedback.
But, at the same time you don&rsquo;t wish to go through the hassle of dealing with MLOps.
This blog post is for you. In this post I will walk you through how to deploy your model and share them to the world for free!</p><h3 id=training-a-model-with-icevision>Training a Model with IceVision</h3><p>We will be using the awesome <a href=https://github.com/airctic/icevision>IceVision</a> object detection package as an example for this post.
IceVision is an agnostic computer vision library pluggable to multiple deep learning frameworks such as <a href=https://github.com/fastai/fastai>Fastai</a> and <a href=https://github.com/PyTorchLightning/pytorch-lightning>PyTorch Lightning</a>.
What makes IceVision awesome is you can train a state-of-the-art object detection models with only few lines of codes.
It&rsquo;s very easy to get started, check out the tutorial <a href=https://github.com/airctic/icevision/blob/master/notebooks/getting_started_object_detection.ipynb>here</a>.</p><p>In the getting started notebook, we use a dataset from <a href=https://github.com/airctic/icedata>Icedata</a> repository known as the <em>Fridge Objects</em> dataset.
This dataset consists 134 images of 4 classes: <em>can</em>, <em>carton</em>, <em>milk bottle</em>, <em>water bottle</em>.
Let&rsquo;s now continue to train our model. Let&rsquo;s train a simple <em>RetinaNet</em> model with a <em>ResNet</em> backbone from <a href=https://github.com/pytorch/vision>Torchvision</a>.
In the notebook, you can easily specify this model using two line of codes as follows.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>model_type <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>torchvision<span style=color:#f92672>.</span>retinanet
backbone <span style=color:#f92672>=</span> model_type<span style=color:#f92672>.</span>backbones<span style=color:#f92672>.</span>resnet50_fpn
</code></pre></div><p>After you&rsquo;re satisfied with the performance of your model, let&rsquo;s save the model into a checkpoint to be used for inferencing later.
With IceVision this can be done easily. Just add the following snippet to your notebook and run.
Feel free to modify the <code>model_name</code>, <code>backbone_name</code> according to the model you used during training.
The <code>img_size</code> argument is image size that the model is trained on.
The <code>classes</code> argument is a list of classes from the dataset.
The <code>filename</code> argument specifies the directory and name of the checkpoint file.
The <code>meta</code> argument stores other metadata that you would like to keep track of for future reference.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> icevision.models.checkpoint <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
save_icevision_checkpoint(learn<span style=color:#f92672>.</span>model,
                        model_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;torchvision.retinanet&#39;</span>, 
                        backbone_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;resnet50_fpn&#39;</span>,
                        img_size<span style=color:#f92672>=</span>image_size,
                        classes<span style=color:#f92672>=</span>parser<span style=color:#f92672>.</span>class_map<span style=color:#f92672>.</span>get_classes(),
                        filename<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;./models/model_checkpoint.pth&#39;</span>,
                        meta<span style=color:#f92672>=</span>{<span style=color:#e6db74>&#39;icevision_version&#39;</span>: <span style=color:#e6db74>&#39;0.12.0&#39;</span>})
</code></pre></div><p>The notebook that I used for this section can be found <a href=https://colab.research.google.com/github/dnth/dnth.github.io/blob/main/static/images/blog/deploy-icevision-hfspace/training_retinanet.ipynb>here</a>.</p><h3 id=user-interface-with-gradio>User Interface with Gradio</h3><p>At this point, in order to run inference on the model, one will need to write inference codes as shown <a href=https://airctic.com/0.12.0/>here</a>.
This is non-trivial especially to people who don&rsquo;t code.
Gradio simplifies this by providing a simple user interface so that anyone can run an inference on the model without having to code.</p><p>The following figure shows a screenshot of the Gradio user interface that runs in the browser.
The left pane shows the input image.
The right pane shows the inference results.
User can upload an image or select from a list of example images and click on <em>Submit</em> to run it through the model for inference.</p><figure><img src=/images/blog/deploy-icevision-hfspace/gradio.png alt="Screenshot of the Onion homepage" width=750></figure><p>In order to use Gradio, we must first install it with <code>pip install gradio</code>.
Next, create a file with the name <code>app.py</code> and paste the following codes into the file.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> gradio.outputs <span style=color:#f92672>import</span> Label
<span style=color:#f92672>from</span> icevision.all <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>from</span> icevision.models.checkpoint <span style=color:#f92672>import</span> <span style=color:#f92672>*</span>
<span style=color:#f92672>import</span> PIL
<span style=color:#f92672>import</span> gradio <span style=color:#f92672>as</span> gr
<span style=color:#f92672>import</span> os

<span style=color:#75715e># Load model</span>
checkpoint_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;model_checkpoint.pth&#34;</span>
checkpoint_and_model <span style=color:#f92672>=</span> model_from_checkpoint(checkpoint_path)
model <span style=color:#f92672>=</span> checkpoint_and_model[<span style=color:#e6db74>&#34;model&#34;</span>]
model_type <span style=color:#f92672>=</span> checkpoint_and_model[<span style=color:#e6db74>&#34;model_type&#34;</span>]
class_map <span style=color:#f92672>=</span> checkpoint_and_model[<span style=color:#e6db74>&#34;class_map&#34;</span>]

<span style=color:#75715e># Transforms</span>
img_size <span style=color:#f92672>=</span> checkpoint_and_model[<span style=color:#e6db74>&#34;img_size&#34;</span>]
valid_tfms <span style=color:#f92672>=</span> tfms<span style=color:#f92672>.</span>A<span style=color:#f92672>.</span>Adapter([<span style=color:#f92672>*</span>tfms<span style=color:#f92672>.</span>A<span style=color:#f92672>.</span>resize_and_pad(img_size), tfms<span style=color:#f92672>.</span>A<span style=color:#f92672>.</span>Normalize()])

<span style=color:#75715e># Populate examples in Gradio interface</span>
examples <span style=color:#f92672>=</span> [
    [<span style=color:#e6db74>&#39;sample_images/1.jpg&#39;</span>],
    [<span style=color:#e6db74>&#39;sample_images/2.jpg&#39;</span>],
    [<span style=color:#e6db74>&#39;sample_images/3.jpg&#39;</span>]
]

<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>show_preds</span>(input_image):
    img <span style=color:#f92672>=</span> PIL<span style=color:#f92672>.</span>Image<span style=color:#f92672>.</span>fromarray(input_image, <span style=color:#e6db74>&#34;RGB&#34;</span>)
    pred_dict <span style=color:#f92672>=</span> model_type<span style=color:#f92672>.</span>end2end_detect(img, valid_tfms, model, 
                                          class_map<span style=color:#f92672>=</span>class_map, 
                                          detection_threshold<span style=color:#f92672>=</span><span style=color:#ae81ff>0.5</span>,
                                          display_label<span style=color:#f92672>=</span>False, 
                                          display_bbox<span style=color:#f92672>=</span>True, 
                                          return_img<span style=color:#f92672>=</span>True, 
                                          font_size<span style=color:#f92672>=</span><span style=color:#ae81ff>16</span>, 
                                          label_color<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;#FF59D6&#34;</span>)
    <span style=color:#66d9ef>return</span> pred_dict[<span style=color:#e6db74>&#34;img&#34;</span>]

gr_interface <span style=color:#f92672>=</span> gr<span style=color:#f92672>.</span>Interface(
    fn<span style=color:#f92672>=</span>show_preds,
    inputs<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;image&#34;</span>],
    outputs<span style=color:#f92672>=</span>[gr<span style=color:#f92672>.</span>outputs<span style=color:#f92672>.</span>Image(type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;pil&#34;</span>, label<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;RetinaNet Inference&#34;</span>)],
    title<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;Fridge Object Detector&#34;</span>,
    description<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;This RetinaNet model detects common objects found in fridge. Upload an image or click an example image below to use.&#34;</span>,
    examples<span style=color:#f92672>=</span>examples,
)
gr_interface<span style=color:#f92672>.</span>launch(inline<span style=color:#f92672>=</span>False, share<span style=color:#f92672>=</span>False, debug<span style=color:#f92672>=</span>True)
</code></pre></div><p>Running <code>app.py</code> loads our model into the Gradio app.
Run the script by typing <code>python app.py</code> in the terminal.
If there are no errors, the terminal will show local URL to access the Gradio app.
You can copy the address and open it with a browser.
The URL address on my machine is <code>http://127.0.0.1:7860/</code>.
The address may vary on your machine.</p><h3 id=huggingface-spaces>HuggingFace Spaces</h3><p>The Gradio app URL link from the previous section can only be accessed locally. But what if you would like to share the link to someone across the internet for free?
In this section, we will discover how to make your Gradio app accessible to anyone by deploying the app on a free platform known as HuggingFace <a href=https://huggingface.co/spaces>Spaces</a>.
Spaces is the new &lsquo;marketplace&rsquo; for various bleeding edge machine learning models.
Many researchers have uploaded interesting models on Space to showcase them as a demo.</p><h4 id=creating-a-space>Creating a Space</h4><p>To host a model on Spaces, you must sign up for an account at <a href=https://huggingface.co/><code>https://huggingface.co/</code></a>.
After that, head over to <a href=https://huggingface.co/spaces><code>https://huggingface.co/spaces</code></a> and click on <strong>Create New Space</strong> button as shown below.</p><figure><img src=/images/blog/deploy-icevision-hfspace/create_new_space.png alt="Screenshot of the Onion homepage" width=750></figure><p>Next fill in the Space name and select a License.
Make sure to select Gradio as the Space SDK and keep the repository <strong>Public</strong>. Click on <strong>Create space</strong> button when you&rsquo;re done.</p><figure><img src=/images/blog/deploy-icevision-hfspace/space_details.png alt="Screenshot of the Onion homepage" width=750></figure><p>Once done, your Space is now ready.
The Space you&rsquo;ve created behaves like a <code>git</code> repository.
You can perform various <code>git</code> related operations such as <code>git clone</code>, <code>git push</code> and <code>git pull</code> to update the repository.
Alternatively, you can also add files into the Space directly using the user interface.</p><figure><img src=/images/blog/deploy-icevision-hfspace/empty_repo.png alt="Screenshot of the Onion homepage" width=750></figure><h4 id=adding-related-files>Adding related files</h4><p>In this blog post, I am going to show you how add files into your Space using the browser.
There are three files required to setup the Space namely <code>app.py</code>, <code>requirements.txt</code>, and <code>packages.txt</code>.</p><p><code>app.py</code> hosts the logic of your application.
This is where the code for the Gradio interface resides. The code is similar to the <code>app.py</code> from the previous section.
This script will be run when the app loads on Hugging Face Space.
<code>requirements.txt</code> lists all the <code>Python</code> packages that will be <code>pip</code>-installed on the Space.
Lastly, <code>packages.txt</code> is special file created to put the OpenCV package to make it work on Spaces
For some reason putting the OpenCV package in the <code>requirements.txt</code> file doesn&rsquo;t work on Space.</p><p>Let&rsquo;s begin to add those files.
Click on the <strong>Files and versions</strong> tab. Next, click on <strong>Add file</strong> and <strong>Create a new file</strong>.
Name your file as <code>app.py</code> and paste the code from the previous section. Click on <strong>Commit new file</strong>.</p><figure><img src=/images/blog/deploy-icevision-hfspace/files_version_tab.png alt="Screenshot of the Onion homepage" width=750></figure><p>If you&rsquo;ve used a <code>mmdetection</code> model, you need to add the following lines at the beginning of the <code>app.py</code> or it will not work.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> subprocess
<span style=color:#f92672>import</span> sys
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;Reinstalling mmcv&#34;</span>)
subprocess<span style=color:#f92672>.</span>check_call([sys<span style=color:#f92672>.</span>executable, <span style=color:#e6db74>&#34;-m&#34;</span>, <span style=color:#e6db74>&#34;pip&#34;</span>, <span style=color:#e6db74>&#34;uninstall&#34;</span>, <span style=color:#e6db74>&#34;-y&#34;</span>, <span style=color:#e6db74>&#34;mmcv-full==1.3.17&#34;</span>])
subprocess<span style=color:#f92672>.</span>check_call([sys<span style=color:#f92672>.</span>executable, <span style=color:#e6db74>&#34;-m&#34;</span>, <span style=color:#e6db74>&#34;pip&#34;</span>, <span style=color:#e6db74>&#34;install&#34;</span>, <span style=color:#e6db74>&#34;mmcv-full==1.3.17&#34;</span>, <span style=color:#e6db74>&#34;-f&#34;</span>, <span style=color:#e6db74>&#34;https://download.openmmlab.com/mmcv/dist/cpu/torch1.10.0/index.html&#34;</span>])
<span style=color:#66d9ef>print</span>(<span style=color:#e6db74>&#34;mmcv install complete&#34;</span>) 
</code></pre></div><p>Add <code>requirements.txt</code> file using the same method. Below are the contents of the file.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>gradio<span style=color:#f92672>==</span>2.4.0
icevision<span style=color:#f92672>[</span>all<span style=color:#f92672>]</span>
mmcv-full<span style=color:#f92672>==</span>1.3.17 -f https://download.openmmlab.com/mmcv/dist/cpu/torch1.10.0/index.html
mmdet<span style=color:#f92672>==</span>2.17.0
</code></pre></div><p>Now, do the same for the last file <code>packages.txt</code> which only has the OpenCV package.</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>python3-opencv
</code></pre></div><p>Finally let&rsquo;s add our checkpoint file <code>model_checkpoint.pth</code>.</p><p>You Space should now contain the three files we&rsquo;ve just added and an additional checkpoint file as shown below.<figure><img src=/images/blog/deploy-icevision-hfspace/done_adding_files.png alt="Screenshot of the Onion homepage" width=750></figure></p><p>A <strong>Building</strong> status should appear indicating that it is setting up by installing the packages and running it upon completion.</p><p>The following is the screenshot on Space.
You can try out the Space yourself <a href=https://huggingface.co/spaces/dnth/webdemo-fridge-detection>here</a>.</p><figure><img src=/images/blog/deploy-icevision-hfspace/screenshot.png alt="Screenshot of the Onion homepage" width=750></figure></div></div></div></div></section></div><section class=footer id=contact><div class=footer__background_shape><svg viewBox="0 0 1920 79"><path d="M0 0h1920v79L0 0z" data-name="Path 1450"/></svg></div><div class=container><div class=row><div class=col-lg-12><div class=footer__cta><div class=shape-1><svg xmlns="http://www.w3.org/2000/svg" width="357" height="315.029" viewBox="0 0 357 315.029"><path data-name="Path 1449" d="M76.1-157.222C91.746-135.8 87.2-94.273 99.993-61.945c12.7 32.328 42.661 55.459 39.248 73.282-3.318 17.823-40.007 30.337-65.6 43.325-25.5 12.988-39.912 26.545-60.01 42.566-20.1 16.116-46.074 34.6-63.328 27.682-17.349-6.921-25.976-39.153-59.915-59.82s-93.1-29.768-105.325-51.478 22.373-56.028 43.609-93.949c21.331-37.921 29.2-79.35 53.563-96.793 24.459-17.444 65.414-10.9 103.9-6.921 38.396 3.982 74.326 5.404 89.965 26.829z" transform="translate(217.489 188.626)"/></svg></div><div class=shape-2><svg xmlns="http://www.w3.org/2000/svg" width="357" height="315.029" viewBox="0 0 357 315.029"><path data-name="Path 1449" d="M76.1-157.222C91.746-135.8 87.2-94.273 99.993-61.945c12.7 32.328 42.661 55.459 39.248 73.282-3.318 17.823-40.007 30.337-65.6 43.325-25.5 12.988-39.912 26.545-60.01 42.566-20.1 16.116-46.074 34.6-63.328 27.682-17.349-6.921-25.976-39.153-59.915-59.82s-93.1-29.768-105.325-51.478 22.373-56.028 43.609-93.949c21.331-37.921 29.2-79.35 53.563-96.793 24.459-17.444 65.414-10.9 103.9-6.921 38.396 3.982 74.326 5.404 89.965 26.829z" transform="translate(217.489 188.626)"/></svg></div><div class="text-light footer__cta_content"><span>Contact me</span><h2 class=mb-0>Let’s Start a Project</h2></div><div class=footer__cta_action><a class="btn btn-light btn-zoom" href=https://dicksonneoh.com/contact>Get in
touch</a></div></div></div></div><div class="row footer__widget"><div class=col-lg-4><div class="footer__widget_logo mb-5"><img src=https://dicksonneoh.com/images/site-navigation/logo_dn_resize.png alt=widget-logo></div></div><div class=col-lg-4><div class="text-light footer__widget_sitemap mb-5"><h4 class=base-font>Sitemap</h4><ul class="unstyle-list small"><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>About me</a></li><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>Frequently Ask Question</a></li><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>Privacy & Policy</a></li><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>Latest Article</a></li></ul></div></div><div class=col-lg-4><div class="text-light footer__widget_address mb-5"><h4 class=base-font>Address</h4><ul class="fa-ul small"><li class=mb-2><a class=text-light href=tel:+%2860%29%203%208921%202020><span class=fa-li><i class="fa fa-phone"></i></span>+(60) 3 8921 2020</a></li><li class=mb-2><a class=text-light href=mailto:dickson.neoh@gmail.com><span class=fa-li><i class="fa fa-envelope"></i></span>dickson.neoh@gmail.com</a></li><li class=mb-2><span class=fa-li><i class="fa fa-map-marker"></i></span>Universiti Tenaga Nasional, 43000, Kajang, Malaysia.</a></li></ul></div></div></div><div class="row footer__footer"><div class=col-lg-6><div class="footer__footer_copy text-light"><p>All right reserved copyright © Dickson Neoh 2022</p></div></div><div class=col-lg-6><div class=footer__footer_social><ul class=unstyle-list><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://www.linkedin.com/in/dickson-neoh-3a6984b8/><i class="fa fa-linkedin-square"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://twitter.com/dicksonneoh7><i class="fa fa-twitter-square"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://github.com/dnth><i class="fa fa-github-square"></i></a></li></ul></div></div></div></div></section><script src="https://maps.googleapis.com/maps/api/js?key=YOUR%20GOOGLE%20MAP%20API&libraries=geometry"></script><script src=https://dicksonneoh.com/plugins/jQuery/jquery.min.js></script><script src=https://dicksonneoh.com/plugins/bootstrap/bootstrap.min.js></script><script src=https://dicksonneoh.com/plugins/slick/slick.min.js></script><script src=https://dicksonneoh.com/plugins/waypoint/jquery.waypoints.min.js></script><script src=https://dicksonneoh.com/plugins/magnafic-popup/jquery.magnific-popup.min.js></script><script src=https://dicksonneoh.com/plugins/tweenmax/TweenMax.min.js></script><script src=https://dicksonneoh.com/plugins/imagesloaded/imagesloaded.min.js></script><script src=https://dicksonneoh.com/plugins/masonry/masonry.min.js></script><script src=https://dicksonneoh.com/js/form-handler.min.js></script><script src=https://dicksonneoh.com/js/script.min.js></script></body></html>