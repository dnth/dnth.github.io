<!doctype html><html><head><meta charset=utf-8><title>Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU</title><meta property="og:title" content="Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU"><meta property="og:description" content="Accelerate inference up to 180+ FPS on a CPU!"><meta property="og:type" content="article"><meta property="og:url" content="https://dicksonneoh.com/portfolio/supercharging_yolov5_180_fps_cpu/"><meta property="og:image" content="https://dicksonneoh.com/images/portfolio/supercharging_yolov5/post_image.png"><meta property="article:section" content="portfolio"><meta property="article:published_time" content="2022-01-19T11:00:15+08:00"><meta property="article:modified_time" content="2022-01-19T11:00:15+08:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dicksonneoh.com/images/portfolio/supercharging_yolov5/post_image.png"><meta name=twitter:title content="Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU"><meta name=twitter:description content="Accelerate inference up to 180+ FPS on a CPU!"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><link rel=stylesheet href=https://dicksonneoh.com/plugins/slick/slick.css><link rel=stylesheet href=https://dicksonneoh.com/plugins/slick/slick-theme.css><link rel=stylesheet href=https://dicksonneoh.com/plugins/font-awesome/css/font-awesome.min.css><link rel=stylesheet href=https://dicksonneoh.com/plugins/magnafic-popup/magnific-popup.css><link href=https://dicksonneoh.com/scss/style.min.css rel=stylesheet><link rel="shortcut icon" href=https://dicksonneoh.com/images/favicon.ico type=image/x-icon><link rel=icon href=https://dicksonneoh.com/images/favicon.png type=image/x-icon><script async src="https://www.googletagmanager.com/gtag/js?id=UA-54500366-2"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","UA-54500366-2")</script></head><body><nav class="navbar navbar-expand-lg fixed-top"><div class=container><a href=https://dicksonneoh.com/ class=navbar-brand><img src=https://dicksonneoh.com/images/site-navigation/logo_dn_resize.png alt=site-logo></a>
<button type=button class="navbar-toggler collapsed" data-toggle=collapse data-target=#navbarCollapse>
<span class=navbar-toggler-icon></span>
<span class=navbar-toggler-icon></span>
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-between" id=navbarCollapse><ul class="nav navbar-nav main-navigation my-0 mx-auto"><li class=nav-item><a href=https://dicksonneoh.com/#home class="nav-link text-dark text-sm-center p-2">Home</a></li><li class=nav-item><a href=https://dicksonneoh.com/#about class="nav-link text-dark text-sm-center p-2">About</a></li><li class=nav-item><a href=https://dicksonneoh.com/#service class="nav-link text-dark text-sm-center p-2">Services</a></li><li class=nav-item><a href=https://dicksonneoh.com/#portfolio class="nav-link text-dark text-sm-center p-2">Projects</a></li><li class=nav-item><a href=https://dicksonneoh.com/#resume class="nav-link text-dark text-sm-center p-2">Resume</a></li><li class=nav-item><a href=https://dicksonneoh.com/#skills class="nav-link text-dark text-sm-center p-2">Skills</a></li><li class=nav-item><a href=https://dicksonneoh.com/#blog class="nav-link text-dark text-sm-center p-2">Blogs</a></li><li class=nav-item><a href=https://dicksonneoh.com/#contact class="nav-link text-dark text-sm-center p-2">Contact</a></li></ul><div class=navbar-nav><a href=https://calendly.com/dickson-neoh/discovery-call rel=noopener class="btn btn-primary btn-zoom hire_button">Book a call</a></div></div></div></nav><div id=content><header class=breadCrumb><div class=container><div class=row><div class="col-lg-10 col-md-12 offset-lg-1 offset-md-0 text-center"><h3 class=breadCrumb__title>Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU</h3><nav aria-label=breadcrumb class="d-flex justify-content-center"></nav></div></div><div class="row p-3"><div class="col-lg-10 col-md-10 offset-lg-1 offset-md-0 text-center"><i class="fa fa-calendar"></i> &ensp;
January 19, 2022 &ensp; &ensp;
<i class="fa fa-clock-o"></i> &ensp;
10 mins read</div><div class="col-lg-10 col-md-12 offset-lg-1 offset-md-0 text-center"><i class="fa fa-tag"></i> &ensp;
<a href=https://dicksonneoh.com/tags/deepsparse/>DeepSparse</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/tags/onnx/>ONNX</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/tags/yolov5/>YOLOv5</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/tags/real-time/>real-time</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/tags/optimization/>optimization</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/tags/pistol/>pistol</a></div><div class="col-lg-10 col-md-12 offset-lg-1 offset-md-0 text-center"><i class="fa fa-folder"></i> &ensp;
<a href=https://dicksonneoh.com/categories/deployment/>deployment</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/categories/object-detection/>object-detection</a>
<span class=separator>â€¢</span>
<a href=https://dicksonneoh.com/categories/modeling/>modeling</a></div></div></div></div></div></header><section class="section singleBlog"><div class=svg-img><img src=https://dicksonneoh.com/images/hero/figure-svg.svg alt></div><div class=animate-shape><img src=https://dicksonneoh.com/images/skill/skill-background-shape.svg alt><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 600 600"><defs><linearGradient id="d" x1=".929" y1=".111" x2=".263" y2=".935" gradientUnits="objectBoundingBox"><stop offset="0" stop-color="#f1f6f9"/><stop offset="1" stop-color="#f1f6f9" stop-opacity="0"/></linearGradient></defs><g data-name="blob-shape (3)"><path class="blob" fill="url(#d)" d="M455.4 151.1c43.1 36.7 73.4 92.8 60.8 136.3-12.7 43.5-68.1 74.4-111.3 119.4-43.1 45-74 104.1-109.8 109-35.9 5-76.7-44.2-111.8-89.2-35.2-45-64.7-85.8-70.8-132.6-6-46.8 11.6-99.6 46.7-136.3 35.2-36.6 88-57.2 142.4-58.8 54.5-1.7 110.6 15.6 153.8 52.2z"/></g></svg></div><div class=animate-pattern><img src=https://dicksonneoh.com/images/service/background-pattern.svg alt=background-shape></div><div class=container><div class=row><div class=col-lg-12><div class=singleBlog__feature><img src=https://dicksonneoh.com/images/portfolio/supercharging_yolov5/post_image.png alt=feature-image></div></div></div><div class="row mt-5"><div class=col-lg-12><div class=singleBlog__content><hr><h3>Table of Contents</h3><nav id=TableOfContents><ul><li><a href=#-motivation>ğŸ”¥ Motivation</a></li><li><a href=#-setting-up>ğŸ”© Setting Up</a><ul><li><a href=#-dataset>ğŸ”« Dataset</a></li><li><a href=#-yolov5-object-detection-library>ğŸ¦¸ YOLOv5 Object Detection Library</a></li></ul></li><li><a href=#-baseline-performance>â›³ Baseline Performance</a><ul><li><a href=#-pytorch>ğŸ”¦ PyTorch</a></li><li><a href=#-deepsparse-engine>ğŸ•¸ DeepSparse Engine</a></li></ul></li><li><a href=#-sparseml-and-recipes>ğŸ‘¨â€ğŸ³ SparseML and Recipes</a><ul><li><a href=#-one-shot>â˜ï¸ One-Shot</a></li><li><a href=#-sparse-transfer-learning>ğŸ¤¹â€â™‚ï¸ Sparse Transfer Learning</a></li><li><a href=#-pruned-yolov5-s>âœ‚ Pruned YOLOv5-S</a></li><li><a href=#-pruned--quantized-yolov5-s>ğŸªš Pruned + Quantized YOLOv5-S</a></li></ul></li><li><a href=#-supercharging-with-smaller-models>ğŸš€ Supercharging with Smaller Models</a></li><li><a href=#-conclusion>ğŸš§ Conclusion</a></li><li><a href=#-comments--feedback>ğŸ™ Comments & Feedback</a></li></ul></nav><hr><style type=text/css>.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fa}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:.125em;position:relative}</style><div><svg width="0" height="0" display="none" xmlns="http://www.w3.org/2000/svg"><symbol id="tip-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.967-111.033 248-248 248S8 392.967 8 256 119.033 8 256 8s248 111.033 248 248zM227.314 387.314l184-184c6.248-6.248 6.248-16.379.0-22.627l-22.627-22.627c-6.248-6.249-16.379-6.249-22.628.0L216 308.118l-70.059-70.059c-6.248-6.248-16.379-6.248-22.628.0l-22.627 22.627c-6.248 6.248-6.248 16.379.0 22.627l104 104c6.249 6.249 16.379 6.249 22.628.001z"/></symbol><symbol id="note-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zm-248 50c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="warning-notice" viewBox="0 0 576 512" preserveAspectRatio="xMidYMid meet"><path d="M569.517 440.013C587.975 472.007 564.806 512 527.94 512H48.054c-36.937.0-59.999-40.055-41.577-71.987L246.423 23.985c18.467-32.009 64.72-31.951 83.154.0l239.94 416.028zM288 354c-25.405.0-46 20.595-46 46s20.595 46 46 46 46-20.595 46-46-20.595-46-46-46zm-43.673-165.346 7.418 136c.347 6.364 5.609 11.346 11.982 11.346h48.546c6.373.0 11.635-4.982 11.982-11.346l7.418-136c.375-6.874-5.098-12.654-11.982-12.654h-63.383c-6.884.0-12.356 5.78-11.981 12.654z"/></symbol><symbol id="info-notice" viewBox="0 0 512 512" preserveAspectRatio="xMidYMid meet"><path d="M256 8C119.043 8 8 119.083 8 256c0 136.997 111.043 248 248 248s248-111.003 248-248C504 119.083 392.957 8 256 8zm0 110c23.196.0 42 18.804 42 42s-18.804 42-42 42-42-18.804-42-42 18.804-42 42-42zm56 254c0 6.627-5.373 12-12 12h-88c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h12v-64h-12c-6.627.0-12-5.373-12-12v-24c0-6.627 5.373-12 12-12h64c6.627.0 12 5.373 12 12v1e2h12c6.627.0 12 5.373 12 12v24z"/></symbol></svg></div><div class="notice info"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#info-notice"/></svg></span>info</p><p>This blog post is still a work in progress. If you require further clarifications before the contents are finalized, please get in touch with me <a href=https://dicksonneoh.com/contact/>here</a>, on <a href=https://www.linkedin.com/in/dickson-neoh/>LinkedIn</a>, or <a href=https://twitter.com/dicksonneoh7>Twitter</a>.</p></div><h3 id=-motivation>ğŸ”¥ Motivation</h3><p>After months of searching, you&rsquo;ve finally found <em>the one</em>.</p><p>The one object detection library that just works.
No installation hassle, no package version mismatch, and no <code>CUDA</code> errors.</p><p>I&rsquo;m talking about the amazingly engineered <a href=https://github.com/ultralytics/yolov5>YOLOv5</a> object detection library by <a href=https://ultralytics.com/yolov5>Ultralytics</a>.</p><p>Elated, you quickly find an interesting dataset from <a href=https://roboflow.com/>Roboflow</a> and finally trained a state-of-the-art (SOTA) YOLOv5 model to detect firearms from image streams.</p><p>You ran through a quick checklist &ndash;</p><ul><li>Inference results, checked âœ…</li><li><code>COCO</code> mAP, checked âœ…</li><li>Live inference latency, checked âœ…</li></ul><p>You&rsquo;re on top of the world.</p><iframe src=https://giphy.com/embed/zEJRrMkDvRe5G width=480 height=360 frameborder=0 class=giphy-embed allowfullscreen></iframe><p><a href=https://giphy.com/gifs/win-zEJRrMkDvRe5G></a></p><p>You can finally pitch the results to your clients next Monday.
At the back of your mind, you can already see your clients&rsquo; impressed look on the astonishing feat.</p><p>On the pitching day, just when you thought things are going in the right direction.
One of the clients asked,</p><p>&ldquo;<strong>Does your model run on our existing CPU?</strong>&rdquo;</p><p>You flinched.</p><p>That wasn&rsquo;t something you anticipated. You tried to convince them that GPUs are <em>&ldquo;the way forward&rdquo;</em> and it&rsquo;s <em>&ldquo;the best way&rdquo;</em> to run your model in real-time.</p><p>You scanned the room and begin to notice the stiff looks on their faces ğŸ‘‡</p><figure><img src=/portfolio/supercharging_yolov5_180_fps_cpu/meme.jpg srcset="/portfolio/supercharging_yolov5_180_fps_cpu/meme_hud55fd9531156531a6f9da4a178f8a462_43912_360x0_resize_q75_box.jpg 360w, /portfolio/supercharging_yolov5_180_fps_cpu/meme_hud55fd9531156531a6f9da4a178f8a462_43912_720x0_resize_q75_box.jpg 720w, /portfolio/supercharging_yolov5_180_fps_cpu/meme_hud55fd9531156531a6f9da4a178f8a462_43912_1920x0_resize_q75_box.jpg 1920w" sizes="(max-width: 37.5em) 360px, (min-width: 75em) 720px, (min-width: 112.5em) 1200px"></figure><p>Needless to say it didn&rsquo;t go well.
I hope nobody will ever have to face this awkward situation in a pitching session, ever.
You don&rsquo;t have to learn it the hard way, like I did.</p><p>You may wonder, can we really use consumer grade CPUs to run models in real-time?</p><p>ğŸ¦¾<strong>YES we can!</strong></p><p>I wasn&rsquo;t a believer, but now I am, after discovering <a href=https://neuralmagic.com/>Neural Magic</a>.</p><p>In this post I show you how you can supercharge your YOLOv5 inference performance running on CPUs using <strong>free</strong> and open-source tools by Neural Magic.</p><div class="notice tip"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#tip-notice"/></svg></span>tip</p><p>By the end of this post, you will learn how to:</p><ul><li>Train a state-of-the-art YOLOv5 model with your own data.</li><li>Sparsify the model using SparseML quantization aware training and one-shot quantization.</li><li>Export the sparsified model and run it using the DeepSparse engine at insane speeds.</li></ul><p><strong>P/S</strong>: The end result - YOLOv5 on CPU at 180+ FPS using only 4 cores! ğŸš€</p></div><p>If that sounds interesting let&rsquo;s get into it â›·.</p><h3 id=-setting-up>ğŸ”© Setting Up</h3><h4 id=-dataset>ğŸ”« Dataset</h4><p>The <a href=https://edition.cnn.com/2022/05/25/us/uvalde-texas-elementary-school-shooting-what-we-know/index.html>recent gun violence</a> news had me thinking deeply about how we can prevent incidents like these again.
This is the worst gun violence since 2012, and 21 innocent lives were lost.</p><p>My heart goes out to all victims of the violence and their loved ones.</p><p>I&rsquo;m not a lawmaker, so there is little I can do there.
But, I think I know something in computer vision that might help.
That&rsquo;s when I came across the <a href=https://public.roboflow.com/object-detection/pistols>Pistols Dataset</a> from Roboflow.</p><p>This dataset contains 2986 images and 3448 labels across a single annotation class: pistols. Images are wide-ranging: pistols in-hand, cartoons, and staged studio quality images of guns. The dataset was originally released by the University of Grenada.</p><figure><img src=/portfolio/supercharging_yolov5_180_fps_cpu/pistol.png srcset="/portfolio/supercharging_yolov5_180_fps_cpu/pistol_hu820a3a10c04a1c82940f2c4154c47bec_81935_360x0_resize_box_3.png 360w, /portfolio/supercharging_yolov5_180_fps_cpu/pistol_hu820a3a10c04a1c82940f2c4154c47bec_81935_720x0_resize_box_3.png 720w, /portfolio/supercharging_yolov5_180_fps_cpu/pistol_hu820a3a10c04a1c82940f2c4154c47bec_81935_1920x0_resize_box_3.png 1920w" sizes="(max-width: 37.5em) 360px, (min-width: 75em) 720px, (min-width: 112.5em) 1200px"></figure><h4 id=-yolov5-object-detection-library>ğŸ¦¸ YOLOv5 Object Detection Library</h4><p>For this post, we are going to use a <a href=https://github.com/neuralmagic/yolov5>forked version</a> of the YOLOv5 library that will allow us to do custom optimizations in the upcoming section.</p><p>To install, run the following commands</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>git clone https://github.com/neuralmagic/yolov5.git
</span></span><span style=display:flex><span>cd yolov5
</span></span><span style=display:flex><span>git checkout release/0.12
</span></span><span style=display:flex><span>pip install -r requirements.txt
</span></span></code></pre></div><p>Now let&rsquo;s put the downloaded Pistols Dataset into the appropriate folder for us to start training.
I will put the downloaded images and labels into the <code>datasets</code> folder.</p><p>Let&rsquo;s also put the sparsification recipes from <a href=https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov5/recipes>SparseML</a> into the <code>recipes</code> folder.</p><p>Here&rsquo;s a high level overview of the structure of the directory.</p><pre tabindex=0><code class=language-tree data-lang=tree>â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ pistols
â”‚   â”‚   â”œâ”€â”€ train
|   |   â”œâ”€â”€ valid
â”œâ”€â”€ recipes
â”‚   â”œâ”€â”€ yolov5s.pruned.md
â”‚   â”œâ”€â”€ yolov5.transfer_learn_pruned.md
â”‚   â”œâ”€â”€ yolov5.transfer_learn_pruned_quantized.md
|   â””â”€â”€ ...
â””â”€â”€ yolov5-train
        â”œâ”€â”€ data
        |   â”œâ”€â”€ hyps
        |   |   â”œâ”€â”€ hyps.scratch.yaml
        |   |   â””â”€â”€ ...
        |   â”œâ”€â”€ pistols.yaml
        |   â””â”€â”€ ...
        â”œâ”€â”€ models_v5.0
        |   â”œâ”€â”€ yolov5s.yaml
        |   â””â”€â”€ ...
        â”œâ”€â”€ train.py
        â”œâ”€â”€ export.py
        â”œâ”€â”€ annotate.py
        â””â”€â”€ ...
</code></pre><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>note</p><ul><li><p><code>datasets</code> - Train/validation labels and images downloaded from Roboflow.</p></li><li><p><code>recipes</code> - Sparsification recipes from the <a href=https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov5/recipes>SparseML</a> repo.</p></li><li><p><code>yolov5-train</code> - cloned directory from Neural Magic&rsquo;s YOLOv5 <a href=https://github.com/neuralmagic/yolov5>fork</a>.</p></li></ul><p>You can explore further into the folder structure on my <a href=https://github.com/dnth/yolov5-deepsparse-blogpost>Github repo</a>.
Feel free to fork repo and use it on your own dataset.</p></div><div class="notice warning"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#warning-notice"/></svg></span>warning</p><p><strong>IMPORTANT</strong>: The sparsification recipes will only work with Neural Magic&rsquo;s YOLOv5 fork and will <strong>NOT WORK</strong> with the original YOLOv5 by Ultralytics.</p></div><h3 id=-baseline-performance>â›³ Baseline Performance</h3><h4 id=-pytorch>ğŸ”¦ PyTorch</h4><p>Now that we have everything in the right place, let&rsquo;s start by training a baseline model with no optimization.</p><p>For that, run the <code>train.py</code> script in the <code>yolov5-train</code> folder.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python train.py --cfg ./models_v5.0/yolov5s.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --data pistols.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --hyp data/hyps/hyp.scratch.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --weights yolov5s.pt --img <span style=color:#ae81ff>416</span> --batch-size <span style=color:#ae81ff>64</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --optimizer SGD --epochs <span style=color:#ae81ff>240</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --project yolov5-deepsparse --name yolov5s-sgd
</span></span></code></pre></div><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>note</p><ul><li><p><code>--cfg</code> &ndash; Path to the configuration file which stores the model architecture.</p></li><li><p><code>--data</code> &ndash; Path to the <code>.yaml</code> file that stores the details of the Pistols dataset.</p></li><li><p><code>--hyp</code> &ndash; Path to the <code>.yaml</code> file that stores the training hyperparameter configurations.</p></li><li><p><code>--weights</code> &ndash; Path to a pretrained weight.</p></li><li><p><code>--img</code> &ndash; Input image size.</p></li><li><p><code>--batch-size</code> &ndash; Batch size used in training.</p></li><li><p><code>--optimizer</code> &ndash; Type of optimizer. Options include <code>SGD</code>, <code>Adam</code>, <code>AdamW</code>.</p></li><li><p><code>--epochs</code> &ndash; Number of training epochs.</p></li><li><p><code>--project</code> &ndash; Wandb project name.</p></li><li><p><code>--name</code> &ndash; Wandb run id.</p></li></ul></div><p>This trains a baseline YOLOv5-S model without any modification. All metrics are logged to Weights & Biases (Wandb). View the training metrics <a href=https://wandb.ai/dnth/yolov5-deepsparse>here</a>.</p><p>Once training completes, let&rsquo;s run an inference on a video with the <code>annotate.py</code> script.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python annotate.py yolov5-deepsparse/yolov5s-sgd/weights/best.pt <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --source data/pexels-cottonbro-8717592.mp4 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --engine torch <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --image-shape <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --device cpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --conf-thres 0.7
</span></span></code></pre></div><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>note</p><p>The first argument points to the <code>.pt</code> saved checkpoint.</p><ul><li><p><code>--source</code> - The input to run inference on. Options: path to video/images or just specify <code>0</code> to infer on your webcam.</p></li><li><p><code>--engine</code> - Which engine to use. Options: <code>torch</code>, <code>deepsparse</code>, <code>onnxruntime</code>.</p></li><li><p><code>--image-size</code> &ndash; Input resolution.</p></li><li><p><code>--device</code> &ndash; Which device to use for inference. Options: <code>cpu</code> or <code>0</code> (GPU).</p></li><li><p><code>--conf-thres</code> &ndash; Confidence threshold for inference.</p></li></ul><p><strong>Note</strong>: The inference result will be saved in the <code>annotation_results</code> folder.</p></div><p>Here&rsquo;s how it looks like running the inference on an Intel i9-11900, 8-core processor using the baseline YOLOv5-S with no optimizations.</p><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/torch-annotation/results_.mp4 type=video/mp4><span></span></video><ul><li>Average FPS : 21.91</li><li>Average inference time (ms) : 45.58</li></ul><p>On a RTX3090 GPU.</p><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/torch-gpu/results_.mp4 type=video/mp4><span></span></video><ul><li>Average FPS : 89.20</li><li>Average inference time (ms) : 11.21</li></ul><p>Frankly, the FPS looks quite decent already and might suit some applications even without further optimization.</p><p>But if you&rsquo;re looking to improve this then read on.</p><h4 id=-deepsparse-engine>ğŸ•¸ DeepSparse Engine</h4><p>DeepSparse engine is an inference engine that runs optimally on CPU.</p><p>It expects a onnx model.</p><p>Let&rsquo;s export our .pt file into onnx using the <code>export.py</code> script.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python export.py --weights yolov5-deepsparse/yolov5s-sgd/weights/best.pt <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --include onnx <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --imgsz <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --dynamic <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --simplify
</span></span></code></pre></div><div class="notice note"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#note-notice"/></svg></span>note</p><p><code>--weight</code> &ndash; Path to the <code>.pt</code> checkpoint.</p><p><code>--include</code> &ndash; Which file to export to. Options: <code>torchscript</code>, <code>onnx</code>, <a href=https://github.com/dnth/yolov5-deepsparse-blogpost/blob/4d44b32909bbc9e8b3bb7f8bf89f0e50361872f7/yolov5-train/export.py#L694>etc</a>.</p><p><code>--imgsz</code> &ndash; Image size.</p><p><code>--dynamic</code> &ndash; Dynamic axes.</p><p><code>--simplify</code> &ndash; Simplify the ONNX model.</p></div><p>Let&rsquo;s run the inference script again, this time using the <code>deepsparse</code> engine and using only 4 CPU cores.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python annotate.py yolov5-deepsparse/yolov5s-sgd/weights/best.onnx <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --source data/pexels-cottonbro-8717592.mp4 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --image-shape <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --conf-thres 0.7 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --engine deepsparse <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --device cpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>        --num-cores <span style=color:#ae81ff>4</span>
</span></span></code></pre></div><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/onnx-annotation/results_.mp4 type=video/mp4><span></span></video><ul><li>Average FPS : 29.48</li><li>Average inference time (ms) : 33.91</li></ul><p>Without any optimization, we improved the FPS from 21 (PyTorch engine on CPU using 8 cores) to 29 just by using the ONNX model with <code>deepsparse</code> engine CPU using 4 cores.</p><p>We are done with the baselines. Let&rsquo;s see how we can start optimizing the model by sparsification.</p><h3 id=-sparseml-and-recipes>ğŸ‘¨â€ğŸ³ SparseML and Recipes</h3><img alt="SparseML Flow" src=https://docs.neuralmagic.com/docs/source/infographics/sparseml.png width=700><p>Sparsification is the process of removing redundant information from a model.
The result is a smaller and faster model.
This is how we can significantly speed up our YOLOv5 model, by a lot!</p><p><a href=https://github.com/neuralmagic/sparseml>SparseML</a> is an open-source library by Neural Magic to sparsify neural networks.
The sparsification is done by applying pre-made recipes to the model.
You can also modify the recipes to suit your needs.</p><p>It currently supports integration with several well known libraries from computer vision and natural language processing domain.</p><p>There are 3 methods to sparsify models with SparseML:</p><ol><li>Post-training (One-shot)</li><li>Sparse Transfer Learning</li><li>Training Aware</li></ol><p><code>1.</code> does not require retraining but only supports dynamic quantization. <code>2.</code> and <code>3.</code> requires retraining and supports pruning and quantization which may give better results.</p><h4 id=-one-shot>â˜ï¸ One-Shot</h4><p>The one-shot method is by far the easiest way to sparsify a model as it doesn&rsquo;t require re-training.</p><p>But this only works well for dynamic quantization for now.
More research works are ongoing on making one-shot work well for pruning.</p><p>Let&rsquo;s run one-shot quantization on the baseline model we trained earlier.
All you need to do is add a <code>--one-shot</code> argument to the training script.
Remember to specify <code>--weights</code> to the location of the best checkpoint from the training.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python train.py --cfg ./models_v5.0/yolov5s.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --data pistols.yaml --hyp data/hyps/hyp.scratch.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --weights yolov5-deepsparse/yolov5s-sgd/weights/best.pt <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --img <span style=color:#ae81ff>416</span> --batch-size <span style=color:#ae81ff>64</span> --optimizer SGD --epochs <span style=color:#ae81ff>240</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --project yolov5-deepsparse --name yolov5s-sgd-one-shot <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --one-shot
</span></span></code></pre></div><p>It should generate another <code>.pt</code> in the directory specified in <code>--name</code>.
This <code>.pt</code> file stores the quantized weights in <code>INT8</code> instead of <code>FLOAT32</code> resulting in a reduction in model size and inference speedups.</p><p>Next we export the quantized .pt file into onnx.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python export.py --weights yolov5-deepsparse/yolov5s-sgd-one-shot/weights/checkpoint-one-shot.pt <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                 --include onnx <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                 --imgsz <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                 --dynamic <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                 --simplify
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python annotate.py yolov5-deepsparse/yolov5s-sgd-one-shot/weights/checkpoint-one-shot.onnx <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --source data/pexels-cottonbro-8717592.mp4 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --image-shape <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>416</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --conf-thres 0.7 <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --engine deepsparse <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --device cpu <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --num-cores <span style=color:#ae81ff>4</span>
</span></span></code></pre></div><ul><li>Average FPS : 32.00</li><li>Average inference time (ms) : 31.24</li></ul><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/one-shot/results_.mp4 type=video/mp4><span></span></video><p>At no retraining cost we are performing 10+ FPS better than the original model with no quantization.
We maxed out at about 40 FPS!</p><h4 id=-sparse-transfer-learning>ğŸ¤¹â€â™‚ï¸ Sparse Transfer Learning</h4><p>Taking an already sparsified (pruned and quantized) and fine-tune it on your own dataset.</p><ul><li>Average FPS : 51.56</li><li>Average inference time (ms) : 19.39</li></ul><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/yolov5s-pruned-quant-tl/results_.mp4 type=video/mp4><span></span></video><h4 id=-pruned-yolov5-s>âœ‚ Pruned YOLOv5-S</h4><p>To sparsify a model we will use pre-made recipes on the SparseML <a href=https://github.com/neuralmagic/sparseml/tree/main/integrations/ultralytics-yolov5/recipes>repo</a>.
These recipes tell the training script how to sparsify the model during training.</p><p>Next, let&rsquo;s train a pruned YOLOv5-S.
For that we slightly modify the command as follows</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>python train.py --cfg ./models_v5.0/yolov5s.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --recipe ../recipes/yolov5s.pruned.md
</span></span><span style=display:flex><span>                --data pistols.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --hyp data/hyps/hyp.scratch.yaml <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --weights yolov5s.pt --img <span style=color:#ae81ff>416</span> --batch-size <span style=color:#ae81ff>64</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --optimizer SGD --epochs <span style=color:#ae81ff>240</span> <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>                --project yolov5-deepsparse --name yolov5s-sgd-pruned
</span></span></code></pre></div><p>The only change here is the <code>--recipe</code> and the <code>--name</code> argument.</p><p><code>--recipe</code> tells the training script to use a sparsification recipe for the YOLOv5-S model.
In this case we are using the <code>yolov5s.pruned.md</code> recipe which prunes the model as it trains.
You can change how aggressive your model is pruned by modifying the <code>yolov5s.pruned.md</code> recipe.</p><ul><li>Average FPS : 35.50</li><li>Average inference time (ms) : 31.73</li></ul><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/yolov5s-pruned/results_.mp4 type=video/mp4><span></span></video><h4 id=-pruned--quantized-yolov5-s>ğŸªš Pruned + Quantized YOLOv5-S</h4><p>Re-training with recipe.</p><ul><li>Average FPS : 58.06</li><li>Average inference time (ms) : 17.22</li></ul><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/yolov5s-pruned-quant/results_.mp4 type=video/mp4><span></span></video><h3 id=-supercharging-with-smaller-models>ğŸš€ Supercharging with Smaller Models</h3><p>Pruned and Quantized YOLOv5n + Hardswish Activation
Hardswish activation performs better with DeepSparse.</p><video controls preload=auto width=700px autoplay loop muted playsinline class=html-video>
<source src=/portfolio/supercharging_yolov5_180_fps_cpu/vids/yolov5n-pruned-quant/results_.mp4 type=video/mp4><span></span></video><ul><li>Average FPS : 93.33</li><li>Average inference time (ms) : 10.71</li></ul><h3 id=-conclusion>ğŸš§ Conclusion</h3><p>I listed all commands I used to train all models on the <a href=https://github.com/dnth/yolov5-deepsparse-blogpost>README</a> of my repo.</p><p>Once the training is done, we have a nice visualization of the metrics on Wandb that compares the mAP.</p><figure><img src=/portfolio/supercharging_yolov5_180_fps_cpu/mAP.png srcset="/portfolio/supercharging_yolov5_180_fps_cpu/mAP_hu0d7a9549a9d7b994410a8d68a69a6c05_401695_360x0_resize_box_3.png 360w, /portfolio/supercharging_yolov5_180_fps_cpu/mAP_hu0d7a9549a9d7b994410a8d68a69a6c05_401695_720x0_resize_box_3.png 720w, /portfolio/supercharging_yolov5_180_fps_cpu/mAP_hu0d7a9549a9d7b994410a8d68a69a6c05_401695_1920x0_resize_box_3.png 1920w" sizes="(max-width: 37.5em) 360px, (min-width: 75em) 720px, (min-width: 112.5em) 1200px"></figure><p>From the graph, it looks like the YOLOv5-S pruned+quantized model performed the best on the mAP.</p><div class="notice tip"><p class="first notice-title"><span class="icon-notice baseline"><svg><use href="#tip-notice"/></svg></span>tip</p><p>In this post you&rsquo;ve learned how to:</p><ul><li>Train a state-of-the-art YOLOv5 model with your own data.</li><li>Sparsify the model using SparseML quantization aware training and one-shot quantization.</li><li>Export the sparsified model and run it using the DeepSparse engine at insane speeds.</li></ul></div><h3 id=-comments--feedback>ğŸ™ Comments & Feedback</h3><p>I hope you&rsquo;ve learned a thing or two from this blog post.
If you have any questions, comments, or feedback, please leave them on the following Twitter post or <a href=https://dicksonneoh.com/contact/>drop me a message</a>.<blockquote class=twitter-tweet><p lang=en dir=ltr>Deploying GPT-like language models on a chatbot is tricky.<br><br>You might wonder<br>â€¢ How to access the model?<br>â€¢ Where to host the bot?<br><br>In this ğŸ§µI walk you through how easily I deployed a GPT-J-6B model by <a href="https://twitter.com/hashtag/EleutherAI?src=hash&ref_src=twsrc%5Etfw">#EleutherAI</a> on a <a href="https://twitter.com/hashtag/Telegram?src=hash&ref_src=twsrc%5Etfw">#Telegram</a> bot with <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw">@huggingface</a> and <a href="https://twitter.com/Gradio?ref_src=twsrc%5Etfw">@Gradio</a>.<br><br>For FREE ğŸš€ <a href=https://t.co/z0uvnxksWt>pic.twitter.com/z0uvnxksWt</a></p>&mdash; Dickson Neoh ğŸš€ (@dicksonneoh7) <a href="https://twitter.com/dicksonneoh7/status/1527512946603020288?ref_src=twsrc%5Etfw">May 20, 2022</a></blockquote><script async src=https://platform.twitter.com/widgets.js></script></p><p>If you like what you see and don&rsquo;t want to miss any of my future content, follow me on Twitter and LinkedIn where I deliver more of these tips in bite-size posts.</p><section class=social-share><ul class=share-icons><hr><h5>Follow me on these platforms ğŸ‘‡</h5><li><a href=https://twitter.com/dicksonneoh7 target=_blank rel=noopener aria-label="Follow on Twitter" class="share-btn twitter"><svg width="6.3503098mm" height="5.1592798mm" viewBox="0 0 6.3503098 5.1592799" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="twitter_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="-38.14813" inkscape:cy="32.360138" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-125.63688,-104.07795)"><path d="m131.98686 104.68815c-.23316.10418-.48452.17363-.74745.20505.26955-.1604.47625-.41672.57216-.72099-.25135.14883-.53082.25797-.82682.31585-.23812-.25136-.57712-.41011-.95084-.41011-.71934.0-1.30308.58374-1.30308 1.30307.0.10253.0116.20175.0331.29601-1.08314-.0546-2.04226-.57216-2.68553-1.36095-.11079.19182-.17528.41672-.17528.65484.0.45145.22985.84997.57877 1.08479-.21332-.007-.41506-.0661-.59035-.16371v.0165c0 .63169.44979 1.15755 1.04511 1.27661-.10914.0298-.2249.0463-.34396.0463-.0843.0-.16537-.008-.24474-.0232.16536.51759.64657.89463 1.21708.90455-.44648.34892-1.00707.55728-1.61726.55728-.10584.0-.20836-.007-.31089-.0182.57712.37041 1.26173.58539 1.9976.58539 2.39614.0 3.70583-1.98438 3.70583-3.70582.0-.0562-.002-.11245-.003-.16868.25466-.18355.47459-.41341.64988-.67468z" id="path1039" style="fill:#fff;stroke-width:.0165365"/></g></svg>&nbsp;
Twitter</a></li>&nbsp;<li><a href=https://www.linkedin.com/in/dickson-neoh/ target=_blank rel=noopener aria-label="Follow on LinkedIn" class="share-btn linkedin"><svg width="6.3499999mm" height="6.3499999mm" viewBox="0 0 6.3499999 6.3499999" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="linkedin_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="-6.2264764" inkscape:cy="40.603642" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-129.66672,-101.87176)"><path d="m129.66672 102.59335v4.90682c0 .39507.32652.72159.72159.72159h4.90682c.39507.0.72159-.32652.72159-.72159v-4.90682c0-.39507-.32652-.72159-.72159-.72159h-4.90682c-.39507.0-.72159.32652-.72159.72159zm5.62841-.14432c.083.0.14432.0613.14432.14432v4.90682c0 .083-.0613.14431-.14432.14431h-4.90682c-.083.0-.14432-.0613-.14432-.14431v-4.90682c0-.083.0613-.14432.14432-.14432zm-4.55504.99219c0 .2742.22189.49609.49609.49609.27421.0.4961-.22189.4961-.49609.0-.27421-.22189-.4961-.4961-.4961-.2742.0-.49609.22189-.49609.4961zm2.30007 1.26278h-.018v-.37883h-.81179v2.74204h.84787v-1.35298c0-.35719.0703-.70355.51413-.70355.43657.0.44198.40409.44198.72159v1.33494h.84787v-1.50632c0-.73783-.15695-1.29886-1.01925-1.29886-.41492.0-.68912.2273-.80277.44197zm-2.21889 2.36321h.85689v-2.74204h-.85689z" id="path1321" style="stroke-width:.0180398;fill:#fff"/></g></svg>&nbsp;
LinkedIn</a></li>&nbsp;<li><a href=https://github.com/dnth/ target=_blank rel=noopener aria-label="Follow on GitHub" class="share-btn github"><svg width="24" height="24" viewBox="0 0 256 250" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" preserveAspectRatio="xMidYMid"><g><path d="M128.00106.0C57.3172926.0.0 57.3066942.0 128.00106c0 56.554221 36.6761997 104.534482 87.534937 121.459839 6.3970853 1.18487999999999 8.745651-2.776734 8.745651-6.157566C96.280588 240.251045 96.1618878 230.167899 96.106777 219.472176 60.4967585 227.215235 52.9826207 204.369712 52.9826207 204.369712c-5.8226623-14.795114-14.2122127-18.729174-14.2122127-18.729174C27.1568785 177.696113 39.6458206 177.859325 39.6458206 177.859325 52.4993419 178.762293 59.267365 191.04987 59.267365 191.04987c11.4164025 19.568553 29.9442103 13.911223 37.2485035 10.640612C97.6647155 193.417512 100.981959 187.77078 104.642583 184.574357 76.211799 181.33766 46.324819 170.362144 46.324819 121.315702c0-13.974813 5.0002398-25.3933338 13.1884247-34.3573083-1.3290169-3.2239785-5.7103208-16.2428317 1.2399917-33.8740301.0.0 10.7487147-3.4401823 35.2094058 13.1205959 10.2103258-2.8360835 21.1604058-4.2583646 32.0384188-4.3071163C138.879073 61.9465949 149.837632 63.368876 160.067033 66.2049595c24.431017-16.5607782 35.164893-13.1205959 35.164893-13.1205959C202.199197 70.715562 197.815773 83.7344152 196.486756 86.9583937 204.694018 95.9223682 209.660343 107.340889 209.660343 121.315702c0 49.163023-29.94421 59.988045-58.447062 63.156912 4.591149 3.97221400000001 8.682061 11.761904 8.682061 23.703979.0 17.126724-.14837399999999 30.910768-.14837399999999 35.12674C159.746968 246.709601 162.05102 250.70089 168.53925 249.443941 219.370432 232.499507 256 184.536204 256 128.00106 256 57.3066942 198.691187.0 128.00106.0zM47.9405593 182.340212C47.6586465 182.976105 46.6581745 183.166873 45.7467277 182.730227 44.8183235 182.312656 44.2968914 181.445722 44.5978808 180.80771 44.8734344 180.152739 45.876026 179.97045 46.8023103 180.409216 47.7328342 180.826786 48.2627451 181.702199 47.9405593 182.340212zm6.2962299 5.618042C53.6263318 188.524199 52.4329723 188.261363 51.6232682 187.366874 50.7860088 186.474504 50.6291553 185.281144 51.2480912 184.70672 51.8776254 184.140775 53.0349512 184.405731 53.8743302 185.298101 54.7115892 186.201069 54.8748019 187.38595 54.2367892 187.958254zM58.5562413 195.146347C57.7719732 195.691096 56.4895886 195.180261 55.6968417 194.042013 54.9125733 192.903764 54.9125733 191.538713 55.713799 190.991845 56.5086651 190.444977 57.7719732 190.936735 58.5753181 192.066505 59.3574669 193.22383 59.3574669 194.58888 58.5562413 195.146347zM65.8613592 203.471174C65.1597571 204.244846 63.6654083 204.03712 62.5716717 202.981538 61.4524999 201.94927 61.1409122 200.484596 61.8446341 199.710926 62.5547146 198.935137 64.0575422 199.15346 65.1597571 200.200564 66.2704506 201.230712 66.6095936 202.705984 65.8613592 203.471174zM75.3025151 206.281542C74.9930474 207.284134 73.553809 207.739857 72.1039724 207.313809 70.6562556 206.875043 69.7087748 205.700761 70.0012857 204.687571 70.302275 203.678621 71.7478721 203.20382 73.2083069 203.659543 74.6539041 204.09619 75.6035048 205.261994 75.3025151 206.281542zM86.046947 207.473627C86.0829806 208.529209 84.8535871 209.404622 83.3316829 209.4237 81.8013 209.457614 80.563428 208.603398 80.5464708 207.564772c0-1.066181 1.20183800000001-1.93311500000002 2.7322209-1.958551C84.8005962 205.576546 86.046947 206.424403 86.046947 207.473627zM96.6021471 207.069023C96.7844366 208.099171 95.7267341 209.156872 94.215428 209.438785 92.7295577 209.710099 91.3539086 209.074206 91.1652603 208.052538 90.9808515 206.996955 92.0576306 205.939253 93.5413813 205.66582 95.054807 205.402984 96.4092596 206.021919 96.6021471 207.069023z" fill="#fff"/></g></svg>&nbsp;
GitHub</a></li>&nbsp;<hr><h5>Share this post ğŸ’¯</h5><li><a href="https://twitter.com/intent/tweet?&url=https%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f&text=Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU @dicksonneoh7" target=_blank rel=noopener aria-label="Share on Twitter" class="share-btn twitter"><svg width="6.3503098mm" height="5.1592798mm" viewBox="0 0 6.3503098 5.1592799" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="twitter_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="-38.14813" inkscape:cy="32.360138" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-125.63688,-104.07795)"><path d="m131.98686 104.68815c-.23316.10418-.48452.17363-.74745.20505.26955-.1604.47625-.41672.57216-.72099-.25135.14883-.53082.25797-.82682.31585-.23812-.25136-.57712-.41011-.95084-.41011-.71934.0-1.30308.58374-1.30308 1.30307.0.10253.0116.20175.0331.29601-1.08314-.0546-2.04226-.57216-2.68553-1.36095-.11079.19182-.17528.41672-.17528.65484.0.45145.22985.84997.57877 1.08479-.21332-.007-.41506-.0661-.59035-.16371v.0165c0 .63169.44979 1.15755 1.04511 1.27661-.10914.0298-.2249.0463-.34396.0463-.0843.0-.16537-.008-.24474-.0232.16536.51759.64657.89463 1.21708.90455-.44648.34892-1.00707.55728-1.61726.55728-.10584.0-.20836-.007-.31089-.0182.57712.37041 1.26173.58539 1.9976.58539 2.39614.0 3.70583-1.98438 3.70583-3.70582.0-.0562-.002-.11245-.003-.16868.25466-.18355.47459-.41341.64988-.67468z" id="path1039" style="fill:#fff;stroke-width:.0165365"/></g></svg>&nbsp;
Twitter</a></li>&nbsp;<li><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f&source=https%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f&title=Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU&summary=Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU" target=_blank rel=noopener aria-label="Share on LinkedIn" class="share-btn linkedin"><svg width="6.3499999mm" height="6.3499999mm" viewBox="0 0 6.3499999 6.3499999" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="linkedin_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="-6.2264764" inkscape:cy="40.603642" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-129.66672,-101.87176)"><path d="m129.66672 102.59335v4.90682c0 .39507.32652.72159.72159.72159h4.90682c.39507.0.72159-.32652.72159-.72159v-4.90682c0-.39507-.32652-.72159-.72159-.72159h-4.90682c-.39507.0-.72159.32652-.72159.72159zm5.62841-.14432c.083.0.14432.0613.14432.14432v4.90682c0 .083-.0613.14431-.14432.14431h-4.90682c-.083.0-.14432-.0613-.14432-.14431v-4.90682c0-.083.0613-.14432.14432-.14432zm-4.55504.99219c0 .2742.22189.49609.49609.49609.27421.0.4961-.22189.4961-.49609.0-.27421-.22189-.4961-.4961-.4961-.2742.0-.49609.22189-.49609.4961zm2.30007 1.26278h-.018v-.37883h-.81179v2.74204h.84787v-1.35298c0-.35719.0703-.70355.51413-.70355.43657.0.44198.40409.44198.72159v1.33494h.84787v-1.50632c0-.73783-.15695-1.29886-1.01925-1.29886-.41492.0-.68912.2273-.80277.44197zm-2.21889 2.36321h.85689v-2.74204h-.85689z" id="path1321" style="stroke-width:.0180398;fill:#fff"/></g></svg>&nbsp;
LinkedIn</a></li>&nbsp;<li><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f" target=_blank rel=noopener aria-label="Share on Facebook" class="share-btn facebook"><svg width="6.3499999mm" height="6.3499999mm" viewBox="0 0 6.3499999 6.3499999" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="facebook_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="-7.8050197" inkscape:cy="32.710925" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-130.36281,-104.14567)"><path d="m130.36281 104.72294v5.19545c0 .3157.26158.57728.57727.57728h5.19546c.3157.0.57727-.26158.57727-.57728v-5.19545c0-.3157-.26157-.57727-.57727-.57727h-5.19546c-.31569.0-.57727.26157-.57727.57727zm5.77273.0v5.19545h-1.4973v-1.94829h.74865l.10824-.86591h-.85689v-.55923c0-.25256.0631-.42394.42393-.42394h.46904v-.78473c-.0794-.0108-.35719-.0271-.67649-.0271-.66567.0-1.11847.40048-1.11847 1.14553v.64943h-.75767v.86591h.75767v1.94829h-2.79617v-5.19545z" id="path1085" style="stroke-width:.0180398;fill:#fff"/></g></svg>&nbsp;
Facebook</a></li>&nbsp;<br><li><a href="https://telegram.me/share/url?text=Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU&url=https%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f" target=_blank rel=noopener aria-label="Share on Telegram" class="share-btn telegram"><svg width="7.3503098mm" height="7.1592798mm" id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 189.473 189.473" style="enable-background:new 0 0 189.473 189.473"><g><path d="M152.531 179.476c-1.48.0-2.95-.438-4.211-1.293l-47.641-32.316-25.552 18.386c-2.004 1.441-4.587 1.804-6.914.972-2.324-.834-4.089-2.759-4.719-5.146l-12.83-48.622L4.821 93.928c-2.886-1.104-4.8-3.865-4.821-6.955-.021-3.09 1.855-5.877 4.727-7.02l174.312-69.36c.791-.336 1.628-.53 2.472-.582.302-.018.605-.018.906-.001 1.748.104 3.465.816 4.805 2.13.139.136.271.275.396.42 1.11 1.268 1.72 2.814 1.835 4.389.028.396.026.797-.009 1.198-.024.286-.065.571-.123.854L159.898 173.38c-.473 2.48-2.161 4.556-4.493 5.523C154.48 179.287 153.503 179.476 152.531 179.476zm-47.669-48.897 42.437 28.785L170.193 39.24l-82.687 79.566 17.156 11.638C104.731 130.487 104.797 130.533 104.862 130.579zM69.535 124.178l5.682 21.53 12.242-8.809-16.03-10.874C70.684 125.521 70.046 124.893 69.535 124.178zM28.136 86.782l31.478 12.035c2.255.862 3.957 2.758 4.573 5.092l3.992 15.129c.183-1.745.974-3.387 2.259-4.624L149.227 38.6 28.136 86.782z" id="path1039" style="fill:#fff;stroke-width:.0165365"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg>&nbsp;
Telegram</a></li>&nbsp;<li><a href="whatsapp://send?text=Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU%2c%20by%20Dickson%20Neoh%20-%20Personal%20Portfolio%0aAccelerate%20inference%20up%20to%20180%2b%20FPS%20on%20a%20CPU%21%0a%0ahttps%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f%0a" target=_blank aria-label="Share on WhatsApp" class="share-btn whatsapp"><svg width="6.0324998mm" height="6.05896mm" viewBox="0 0 6.0324997 6.05896" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="whatsapp_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="4.9987205" inkscape:cy="35.692618" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-126.67735,-103.17712)"><path d="m131.83672 104.07671c-.58208-.58209-1.34937-.89959-2.14312-.89959-1.64042.0-2.98979 1.34938-2.98979 3.01625.0.52917.13229 1.03188.39687 1.48167l-.42333 1.56104 1.5875-.42333c.42333.23812.92604.34396 1.42875.34396 1.66687.0 3.01625-1.34938 3.01625-3.01625-.0265-.74084-.3175-1.50813-.87313-2.06375zm-2.14312 4.6302c-.44979.0-.87313-.13229-1.27-.34395l-.10583-.0529-.92605.26458.26459-.89958-.0794-.13229c-.26458-.39688-.37041-.84667-.37041-1.34938.0-1.37583 1.11125-2.48708 2.48708-2.48708.66146.0 1.29646.26458 1.77271.74083.47625.47625.74083 1.11125.74083 1.77271-.0265 1.37583-1.13771 2.48708-2.51354 2.48708zm1.34937-1.87854c-.0794-.0265-.44979-.23812-.5027-.26458-.0794-.0265-.1323-.0265-.18521.0265-.0529.0794-.21167.26458-.23813.29104-.0529.0529-.0794.0529-.15875.0265-.0794-.0265-.3175-.13229-.60854-.37042-.23812-.21167-.37042-.44979-.42333-.52917-.0529-.0794.0-.13229.0265-.15875.0265-.0264.0794-.0794.10583-.13229.0529-.0265.0794-.0794.10583-.13229.0265-.0529.0-.10583.0-.13229.0-.0265-.18521-.39688-.26458-.55563-.0265-.10583-.10583-.0794-.13229-.0794h-.15875s-.10584.0265-.18521.0794c-.0794.0794-.26458.26459-.26458.635.0.37042.26458.74084.29104.79375.0265.0529.52916.82021 1.29646 1.13771.1852.0794.3175.13229.42333.15875.18521.0529.34396.0529.47625.0265.15875-.0265.44979-.18521.50271-.34396.0529-.18521.0529-.3175.0529-.34396-.0264-.0794-.0794-.10583-.15875-.13229z" id="path1793" style="stroke-width:.264583;fill:#fff"/></g></svg>&nbsp;
WhatsApp</a></li>&nbsp;<li><a href="mailto:?subject=Dickson%20Neoh%20-%20Personal%20Portfolio - Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU.&body=Supercharging%20YOLOv5%3a%20How%20I%20Got%20182.4%20FPS%20Inference%20Without%20a%20GPU%2c%20by%20Dickson%20Neoh%20-%20Personal%20Portfolio%0aAccelerate%20inference%20up%20to%20180%2b%20FPS%20on%20a%20CPU%21%0a%0ahttps%3a%2f%2fdicksonneoh.com%2fportfolio%2fsupercharging_yolov5_180_fps_cpu%2f%0a" target=_blank class="share-btn email" aria-label="Share via Email"><svg width="6.3499999mm" height="4.3961601mm" viewBox="0 0 6.3499999 4.3961601" id="svg5" inkscape:version="1.1.2 (b8e25be833, 2022-02-05)" sodipodi:docname="email_white.svg" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape" xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd" xmlns="http://www.w3.org/2000/svg" xmlns:svg="http://www.w3.org/2000/svg"><sodipodi:namedview id="namedview7" pagecolor="#ffffff" bordercolor="#666666" borderopacity="1" inkscape:pageshadow="2" inkscape:pageopacity="0" inkscape:pagecheckerboard="0" inkscape:document-units="mm" showgrid="false" inkscape:zoom="5.701459" inkscape:cx="-6.7526575" inkscape:cy="33.4125" inkscape:window-width="1920" inkscape:window-height="972" inkscape:window-x="1920" inkscape:window-y="1107" inkscape:window-maximized="1" inkscape:current-layer="layer1"/><defs id="defs2"/><g inkscape:label="Layer 1" inkscape:groupmode="layer" id="layer1" transform="translate(-130.10375,-103.97942)"><path d="m130.10375 104.22365v3.9077.24423h.24423 5.86154.24423v-.24423-3.9077-.24423h-.24423-5.86154-.24423zm5.29675.24423-2.12175 1.41196-2.12175-1.41196zm-2.25913 1.91569.13738.0839.13738-.0839 2.54916-1.70198v3.20553h-5.37308v-3.20553z" id="path824" style="stroke-width:.0152644;fill:#fff"/></g></svg>&nbsp;
Email</a></li><hr><section><h5>I need your help ğŸ¤’</h5><a href=https://calendly.com/dickson-neoh/discovery-call target=_blank><img src=https://raw.githubusercontent.com/dnth/dnth.github.io/main/static/images/site-navigation/seeking.gif width=700></a><p>âš ï¸ The pandemic has impacted my day job.
I'm seeking remote employment opportunities as a Data Scientist or Machine Learning Engineer.
If you know of any openings, I'd be forever grateful if you can connect me.</p><p>Or, if you wish to support me in creating more contents on machine learning deployment tips and tricks, consider buying me a coffee. Your support means a lot ğŸ¤—</p></section><section><div style=text-align:center><a href=https://www.buymeacoffee.com/dicksonneoh target=_blank><img src=https://cdn.buymeacoffee.com/buttons/v2/default-blue.png alt="Buy Me A Coffee" style=height:60px!important;width:217px!important></a></div>Thank you!!</section><hr></ul></section></div></div></div><div class=row><div class="col-lg-10 offset-lg-1"><nav class="case-details-nav d-flex justify-content-between align-items-center"><div class="px-4 bg-primary"></div><div class="next d-flex align-items-center"><div class="content text-right"><span class=small>Next blog</span><h5 class=title><a class=text-dark href=https://dicksonneoh.com/portfolio/deploy_icevision_models_on_huggingface_spaces/>Deploying Object Detection Models on Hugging Face Spaces</a></h5></div><div class="icon ml-3"><svg xmlns="http://www.w3.org/2000/svg" width="15.556" height="28.285" viewBox="0 0 15.556 28.285"><g data-name="Group 1244" fill="#2d2d2d"><path data-name="Path 1456" d="M12.162 12.725 2.416 26.87l.978 1.41 9.746-14.138z"/><path data-name="Path 1455" d="M2.416 1.415l9.743 14.141.975-1.414L3.39.0z"/></g></svg></div></div></nav></div></div></div></section></div><section class=footer id=contact><div class=footer__background_shape><svg viewBox="0 0 1920 79"><path d="M0 0h1920v79L0 0z" data-name="Path 1450"/></svg></div><div class=container><div class=row><div class=col-lg-12><div class=footer__cta><div class=shape-1><svg xmlns="http://www.w3.org/2000/svg" width="357" height="315.029" viewBox="0 0 357 315.029"><path data-name="Path 1449" d="M76.1-157.222C91.746-135.8 87.2-94.273 99.993-61.945c12.7 32.328 42.661 55.459 39.248 73.282-3.318 17.823-40.007 30.337-65.6 43.325-25.5 12.988-39.912 26.545-60.01 42.566-20.1 16.116-46.074 34.6-63.328 27.682-17.349-6.921-25.976-39.153-59.915-59.82s-93.1-29.768-105.325-51.478 22.373-56.028 43.609-93.949c21.331-37.921 29.2-79.35 53.563-96.793 24.459-17.444 65.414-10.9 103.9-6.921 38.396 3.982 74.326 5.404 89.965 26.829z" transform="translate(217.489 188.626)"/></svg></div><div class=shape-2><svg xmlns="http://www.w3.org/2000/svg" width="357" height="315.029" viewBox="0 0 357 315.029"><path data-name="Path 1449" d="M76.1-157.222C91.746-135.8 87.2-94.273 99.993-61.945c12.7 32.328 42.661 55.459 39.248 73.282-3.318 17.823-40.007 30.337-65.6 43.325-25.5 12.988-39.912 26.545-60.01 42.566-20.1 16.116-46.074 34.6-63.328 27.682-17.349-6.921-25.976-39.153-59.915-59.82s-93.1-29.768-105.325-51.478 22.373-56.028 43.609-93.949c21.331-37.921 29.2-79.35 53.563-96.793 24.459-17.444 65.414-10.9 103.9-6.921 38.396 3.982 74.326 5.404 89.965 26.829z" transform="translate(217.489 188.626)"/></svg></div><div class="text-light footer__cta_content"><span>Contact me</span><h2 class=mb-0>Letâ€™s Start a Project</h2></div><div class=footer__cta_action><a class="btn btn-light btn-zoom" href=https://dicksonneoh.com/contact>Get in
touch</a></div></div></div></div><div class="row footer__widget"><div class=col-lg-4><div class="footer__widget_logo mb-5"><img src=https://dicksonneoh.com/images/site-navigation/logo_dn_resize.png alt=widget-logo></div></div><div class=col-lg-4><div class="text-light footer__widget_sitemap mb-5"><h4 class=base-font>Sitemap</h4><ul class="unstyle-list small"><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>About me</a></li><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>Frequently Ask Question</a></li><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>Privacy & Policy</a></li><li class=mb-2><a class=text-light href=https://dicksonneoh.com/>Latest Article</a></li></ul></div></div><div class=col-lg-4><div class="text-light footer__widget_address mb-5"><h4 class=base-font>Address</h4><ul class="fa-ul small"><li class=mb-2><a class=text-light href=tel:+%2860%29%203%208921%202020><span class=fa-li><i class="fa fa-phone"></i></span>+(60) 3 8921 2020</a></li><li class=mb-2><a class=text-light href=mailto:dickson.neoh@gmail.com><span class=fa-li><i class="fa fa-envelope"></i></span>dickson.neoh@gmail.com</a></li><li class=mb-2><span class=fa-li><i class="fa fa-map-marker"></i></span>Universiti Tenaga Nasional, 43000, Kajang, Malaysia.</a></li></ul></div></div></div><div class="row footer__footer"><div class=col-lg-6><div class="footer__footer_copy text-light"><p>All right reserved copyright Â© Dickson Neoh 2022</p></div></div><div class=col-lg-6><div class=footer__footer_social><ul class=unstyle-list><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://www.linkedin.com/in/dickson-neoh/><i class="fa fa-linkedin-square"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://twitter.com/dicksonneoh7><i class="fa fa-twitter-square"></i></a></li><li class="d-inline-block mx-2"><a class=text-light target=_blank href=https://github.com/dnth><i class="fa fa-github-square"></i></a></li></ul></div></div></div></div></section><script src="https://maps.googleapis.com/maps/api/js?key=YOUR%20GOOGLE%20MAP%20API&libraries=geometry"></script>
<script src=https://dicksonneoh.com/plugins/jQuery/jquery.min.js></script>
<script src=https://dicksonneoh.com/plugins/bootstrap/bootstrap.min.js></script>
<script src=https://dicksonneoh.com/plugins/slick/slick.min.js></script>
<script src=https://dicksonneoh.com/plugins/waypoint/jquery.waypoints.min.js></script>
<script src=https://dicksonneoh.com/plugins/magnafic-popup/jquery.magnific-popup.min.js></script>
<script src=https://dicksonneoh.com/plugins/tweenmax/TweenMax.min.js></script>
<script src=https://dicksonneoh.com/plugins/imagesloaded/imagesloaded.min.js></script>
<script src=https://dicksonneoh.com/plugins/masonry/masonry.min.js></script>
<script src=https://dicksonneoh.com/js/form-handler.min.js></script>
<script src=https://dicksonneoh.com/js/script.min.js></script></body></html>