<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>TIMM on Dickson Neoh - Personal Portfolio</title><link>https://dicksonneoh.com/tags/timm/</link><description>Recent content in TIMM on Dickson Neoh - Personal Portfolio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 16 Sep 2023 11:00:15 +0800</lastBuildDate><atom:link href="https://dicksonneoh.com/tags/timm/index.xml" rel="self" type="application/rss+xml"/><item><title>Unlocking Edge ML: From PyTorch Image Models (TIMM) to ONNX/Torchscript</title><link>https://dicksonneoh.com/blog/unlocking_edge_ml_from_timm_to_onnx_torchscript/</link><pubDate>Sat, 16 Sep 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/unlocking_edge_ml_from_timm_to_onnx_torchscript/</guid><description>ðŸš€ Motivation: Why Edge Deployment? It&amp;rsquo;s late 2023, everyone seems to be talking about complex and larger models.
Sophisticated models perform well at specific tasks. But they come with the cost of massive computational power. And typically that&amp;rsquo;s available only in cloud-based environments. Cloud-based environments come with limitations, such as latency, bandwidth constraints, and sometimes even privacy concerns.
This is when edge deployment comes into play.
In simple terms, edge deployment means running a model close to the source of the data.</description></item><item><title>Bringing High-Quality Image Models to Mobile: Hugging Face TIMM Meets Android &amp; iOS</title><link>https://dicksonneoh.com/portfolio/bringing_high_quality_image_models_to_mobile/</link><pubDate>Thu, 16 Mar 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/bringing_high_quality_image_models_to_mobile/</guid><description>ðŸŒŸ Motivation For many data scientist (including myself), we pride ourselves in training a model, seeing the loss graph go down, and claim victory when the test set accuracy reaches 99.99235%.
Why not?
This is the after all the juiciest part of the job. &amp;ldquo;Solving&amp;rdquo; one dataset after another, it may seem like anything around you can be conquered with a simple model.fit.
That was me two years ago.
The naive version of me thought that was all about it with machine learning (ML).</description></item><item><title>PyTorch at the Edge: Deploying Over 964 TIMM Models on Android with TorchScript and Flutter</title><link>https://dicksonneoh.com/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</link><pubDate>Tue, 07 Feb 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/pytorch_at_the_edge_timm_torchscript_flutter/</guid><description>ðŸ”¥ Motivation With various high-level libraries like Keras, Transformer, and Fastai, the barrier to training SOTA models has never been lower.
On top of that with platforms like Google Colab and Kaggle, pretty much anyone can train a reasonably good model using an old laptop or even a mobile phone (with some patience).
The question is no longer &amp;ldquo;can we train a SOTA model?&amp;rdquo;, but &amp;ldquo;what happens after that?&amp;rdquo;
Unfortunately, after getting the model trained, most people wash their hands off at this point claiming their model works.</description></item></channel></rss>