<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>PyTorch on Dickson Neoh - Personal Portfolio</title><link>https://dicksonneoh.com/tags/pytorch/</link><description>Recent content in PyTorch on Dickson Neoh - Personal Portfolio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sat, 16 Sep 2023 11:00:15 +0800</lastBuildDate><atom:link href="https://dicksonneoh.com/tags/pytorch/index.xml" rel="self" type="application/rss+xml"/><item><title>Unlocking Edge ML: From PyTorch Image Models (TIMM) to ONNX/Torchscript</title><link>https://dicksonneoh.com/blog/unlocking_edge_ml_from_timm_to_onnx_torchscript/</link><pubDate>Sat, 16 Sep 2023 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/blog/unlocking_edge_ml_from_timm_to_onnx_torchscript/</guid><description>ðŸš€ Motivation: Why Edge Deployment? It&amp;rsquo;s late 2023, everyone seems to be talking about complex and larger models.
Sophisticated models perform well at specific tasks. But they come with the cost of massive computational power. And typically that&amp;rsquo;s available only in cloud-based environments. Cloud-based environments come with limitations, such as latency, bandwidth constraints, and sometimes even privacy concerns.
This is when edge deployment comes into play.
In simple terms, edge deployment means running a model close to the source of the data.</description></item></channel></rss>