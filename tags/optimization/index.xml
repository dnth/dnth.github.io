<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>optimization on Dickson Neoh - Personal Portfolio</title><link>https://dicksonneoh.com/tags/optimization/</link><description>Recent content in optimization on Dickson Neoh - Personal Portfolio</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 07 Jun 2022 11:00:15 +0800</lastBuildDate><atom:link href="https://dicksonneoh.com/tags/optimization/index.xml" rel="self" type="application/rss+xml"/><item><title>Supercharging YOLOv5: How I Got 182.4 FPS Inference Without a GPU</title><link>https://dicksonneoh.com/portfolio/supercharging_yolov5_180_fps_cpu/</link><pubDate>Tue, 07 Jun 2022 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/supercharging_yolov5_180_fps_cpu/</guid><description>ðŸ”¥ Motivation After months of searching, you&amp;rsquo;ve finally found the one.
The one object detection library that just works. No installation hassle, no package version mismatch, and no CUDA errors.
I&amp;rsquo;m talking about the amazingly engineered YOLOv5 object detection library by Ultralytics.
Elated, you quickly find an interesting dataset from Roboflow and finally trained a state-of-the-art (SOTA) YOLOv5 model to detect firearms from image streams.
You ran through a quick checklist &amp;ndash;</description></item><item><title>Squeezing the Best Performance Out of YOLOX with Weights and Biases</title><link>https://dicksonneoh.com/portfolio/comparing_yolox_models_weights_and_biases/</link><pubDate>Wed, 11 May 2022 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/comparing_yolox_models_weights_and_biases/</guid><description>ðŸ”Ž Motivation .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative} tip
By the end of this post you will learn how to:
Install the Weights and Biases client and log the YOLOX training metrics. Compare training metrics on Weights and Biases dashboard. Picking the best model with mAP and FPS values. &amp;ldquo;So many models, so little time!&amp;rdquo;
As a machine learning engineer, I often hear this phrase thrown around in many variations.</description></item><item><title>Faster than GPU: How to 10x your Object Detection Model and Deploy on CPU at 50+ FPS</title><link>https://dicksonneoh.com/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</link><pubDate>Sat, 30 Apr 2022 15:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/how_to_10x_your_od_model_and_deploy_50fps_cpu/</guid><description>ðŸš¦ Motivation .notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative} tip
By the end of this post, you will learn how to:
Train state-of-the-art YOLOX model with your own data. Convert the YOLOX PyTorch model into ONNX and OpenVINO IR format. Run quantization algorithm to 10x your model&amp;rsquo;s inference speed. P/S: The final model runs faster on the CPU than the GPU!</description></item><item><title>TIMM at the Edge: Deploying Over 964 PyTorch Image Models on Android with TorchScript and Flutter</title><link>https://dicksonneoh.com/portfolio/timm_torchscript_flutter/</link><pubDate>Sun, 09 Jan 2022 11:00:15 +0800</pubDate><guid>https://dicksonneoh.com/portfolio/timm_torchscript_flutter/</guid><description>.notice{padding:18px;line-height:24px;margin-bottom:24px;border-radius:4px;color:#6c757d;background:#e7f2fa}.notice p:last-child{margin-bottom:0}.notice-title{margin:-18px -18px 12px;padding:4px 18px;border-radius:4px 4px 0 0;font-weight:700;color:#fff;background:#6ab0de}.notice.warning .notice-title{background:rgba(217,83,79,.9)}.notice.warning{background:#fae2e2}.notice.info .notice-title{background:#f0b37e;}.notice.info{background:#fff2db}.notice.note .notice-title{background:#6ab0de}.notice.note{background:#e7f2fA}.notice.tip .notice-title{background:rgba(92,184,92,.8)}.notice.tip{background:#e6f9e6}.icon-notice{display:inline-flex;align-self:center;margin-right:8px}.icon-notice img,.icon-notice svg{height:1em;width:1em;fill:currentColor}.icon-notice img,.icon-notice.baseline svg{top:0.125em;position:relative} info
This blog post is still a work in progress. If you require further clarifications before the contents are finalized, please get in touch with me here, on LinkedIn, or Twitter. ðŸ”¥ Motivation You finally got into a Kaggle competition. You found a getting-started notebook written by a Kaggle Grandmaster and immediately trained a state-of-the-art (SOTA) image classification model.</description></item></channel></rss>